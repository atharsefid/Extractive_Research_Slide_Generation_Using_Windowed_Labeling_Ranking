When the Australian secret ballot was introduced in the 1850s, it not only provided privacy for those voters who wanted it, but it also effectively eliminated coercion by allowing no viable means for voters to prove their votes to third parties.
In an environment where the privacy of voters is enforced by independent observers, coerced voters could freely express their true preferences while making their selections.
In contrast, modern technologies render the traditional poll-site protections largely ineffective, and the limited remaining options for preserving these protections will almost certainly disappear in the not-too-distant future.
Today, in-person voters routinely carry video recording equipment and other technologies that facilitate coercion into polls, and although not yet ubiquitous, inexpensive and unobtrusive wearable video recording devices are readily available.
In view of these realities, it is appropriate to reexamine the efforts and countermeasures currently employed and explore what defenses are possible and reasonable against various forms of voter coercion.
The Australian ballot is regarded as the gold standard of voting.
For over a century, coercion has been effectively thwarted by the process of compelling voters to mark and cast their ballots in an environment where their privacy is enforced by independent monitors.
Although they are common in many jurisdictions, remote voting systems such as vote-by-mail are generally regarded as providing inferior protection from coercion, and as such, their use is often discouraged by experts.The design of new voting systems is heavily influenced by measures intended to thwart coercion.
If they can't match the gold standard of the Australian ballot, these systems risk out of hand rejection.
To meet "best practices", new systems often include elaborate and complex procedures such as printing behind a screen so that a commitment made by a voting device cannot be seen by a voter until a subsequent step in the process ( [Neff 2004], [Chaum et al. 2005], [Moran and Naor 1997], [Benaloh 2007], [Benaloh 2008], [Chaum et al. 2009], [Küsters and Truderung 2009], [Küsters et al. 2010], [Juels et al. 2010], [Araujo et al. 2010]).
However, the ubiquity of cell phones gives many voters an easy means to record their entire voting sessions and show them to third parties.
Even more alarming, video cameras are now available surreptitiously embedded in clothing and eyeglasses, 1 and no effective means to eliminate this threat is evident.
As miniaturization continues, costs decrease, and new applications and innovations are promulgated, attempts to prevent voters from recording their voting sessions will become increasingly futile.
With current technologies, a coercer can demand that a victimized voter wear a video recorder, establish identity by standing before a mirror (perhaps in a bathroom near a poll site), and then move into a poll site to vote.
The entire unbroken process can be recorded as a continuous video stream.
Anyone wishing to voluntarily sell a vote can produce a similar video stream.Because of these emerging threats, the gold standard of the Australian ballot is losing its luster, and the hope of preventing all forms of voter coercion is waning.
In this light, it is appropriate to categorize the different forms of coercion and analyze what forms of coercion can reasonably be controlled and to also address the impacts of these realities on election system design.
There are many different types of coercion and vote-selling, but they can be partitioned and classified across a small number of axes.
It will be seen that, perhaps surprisingly, some axes which seem significant are not.
For instance, it turns out that from the perspective of mitigation, vote-selling (voluntary) and coercion (involuntary) are surprisingly similar.
For this reason, the general term co-ercion will often be used to describe both cases.
A more thorough treatment of the distinctions will be given below.
It is very difficult to imagine strong defenses against a concerted pre-planned attack by a determined adversary.
The example where a voter wears a hidden camera to first capture the voter's identity (either directly or with a mirror) and then record the voter's complete interactions within a poll site is compelling.
However, such an effort must be planned.
As wearable cameras become more common, it might be possible for voters to inadvertently record themselves voting and then subsequently decide to offer this recording as proof of a particular selection, but it is not yet likely that a voter can be coerced into revealing a vote after the fact.
People who are not being coerced and have no intention to subsequently sell their votes can generally be expected to heed requests to turn off recording equipment prior to voting.
Thus, under "normal" circumstances, a voter who has not been coerced and follows well-constructed instructions through the voting process should not be coercible afterwards.It would therefore seem that an important design principle of voting systems would be to preclude "after the fact" coercion.
Examples of systems that fail to satisfy this principle would include systems that do not instruct voters to disable recording devices and systems that provide voters with (authenticated) take-home receipts that reveal their selections.There is a close analogy here with deniable encryption.
The original protocols for deniable encryption ( [Canetti et al. 1997]) put substantial effort into allowing the sender of an encrypted message to avoid divulging its contents to a coercer.
However, the protocol required randomness, and a "before the fact" attacker could simply provide the target with a source of randomness and require its use -thereby defeating the protocol.
By contrast, any randomized encryption protocol that calls for the sender to delete the relevant random values before sending provides a strong defense against an "after the fact" request to disclose the encrypted value.
The conclusion there was that any common randomized encryption scheme can provide good protection against a post-protocol disclosure request, but no system can provide full protection against a coercive attack that is launched prior to the execution of the encryption protocol unless a secondary "untappable" channel is available to which the attacker has no access.Analysis of an assumption of a physically untappalbe channel for elections goes back to at least [Benaloh and Tuinstra 1994] and has been leveraged heavily in well-known protocols such as [Hirt and Sako 2000] and [Juels et al. 2010].
[Hirt 2001] explores the limits of voting without this assumption and makes a strong case that coercion cannot be prevented without an untappable channel.
While a properly constructed and managed physical poll-site could serve as an embodiment of an untappable channel a decade ago, surreptitious wearable video cameras now render poll-sites as an ineffective means of achieving an untappable channel, and no alternative is evident.
Without the ability to construct an untappable channel, pre-election coercion is virtually impossible to thwart in practice.A middle ground may be available if coercion takes place after registration but before voting.
Some remote voting protocols such as [Juels et al. 2010] assume that voters are able to obtain information during registration that protects them from coercion during subsequent voting.
If voters are coerced prior to registration, the same surreptitious video recording technique can be used by a coercer to obtain credentials or other data from prospective voters.
However, voters who are not coerced until after registration may be protected so long as the protocol is engineered to not allow the voter to offer "proof" of the secret registration data.
In [Juels et al. 2010] there is an additional assumption that voters have some private time to use their credentials to cast their true votesalthough one can imagine protocols where this additional assumption is not necessary.
2 Some remote protocols (e.g. Helios - [Adida 2008]) attempt to use a "last vote counts" strategy to allow voters who have been coerced to return later to cast their true votes.
However, this class of strategies is easily thwarted by a coercer who requires voters to vote at the end of the voting period or to continue uninterrupted video recording from the time of the vote through the end of the voting period.While it may initially appear impractical for a coercer to monitor the video recordings of a large number of voters, two observations show that wholesale coercion is both possible and practical.
First, video recordings can be viewed at a much faster speed than that at which they were made.
This, for example, makes it practical for a coercer to observe that a voter who cast a vote early in the day did not return to cast a subsequent overriding vote.
Second, and even more devastating, is the opportunity for coercers to use simple random sampling.
An employee who risks the loss of a job for not voting as instructed may be unlikely to attempt to skirt the coercion -even if the chance of the employer viewing the video and discovering the employee's "indiscretion" is only 1 in 100.
While it may initially seem as though there might be a substantial difference between involuntary coercion and voluntary vote-selling, closer examination shows that the differences are small.
In the pre-election case, a voter who can be involuntarily coerced can voluntarily ask to be coerced by a potential buyer of the vote, and a voter who can convince a purchaser of the contents of a vote can offer the same proof to a coercer.
Although this is by no means a formal reduction, it demonstrates a rough equivalence between the two cases.There are, of course, some differences between the two cases.
It is easier, for instance, to purchase 100 votes from willing sellers than to exhort 100 otherwise unwilling individuals with threats and intimidation, and large-scale coercion is likely to be even more difficult if the protocol requires it to be initiated well before the actual voting takes place.
However, if we focus attention on a single voter and a well-resourced attacker who can make good on viable threats, then the unwillingly-coerced voter has little more protection than the voter willing to sell a vote.One might look for a distinction by exploring a case where a voter takes pre-election steps in order to sell a vote to an (as yet unknown) post-election purchaser.
But there are problems with this scenario.
First, once a voter has completed a vote, there is no clear advantage to a potential votebuyer to pay for a vote that has already been cast and can no longer be changed.
Second, even if we imagine that a voter is simply aware of a vague rumor that a particular vote might be rewarded after the election and that rumor turns out to be true and is backed up by post-election specifics, a voter can -as with the involuntary case -preserve a full record (video recording, derive "randomness" deterministically from a preserved seed, etc.)In the post-election case, it's clear that good secret-ballot election protocols can and should allow neither voluntary nor involuntary disclosure of a voter's selections.
Once the voting process is complete, a voter who has not taken any prior actions to preserve the record of a vote should be unable to prove details about a vote to third-parties, and virtually every extent election protocol satisfies this property.
Traditionally, local coercion has been seen as easier to implement than remote coercion.
A coercer who can be located within a polling site and who can watch and perhaps even signal a voter can have more coercion options that one who is not present.
Some voting protocols (e.g. STAR-vote [Benaloh et al. 2012] and VeriScan [Benaloh 2008]) allow a voter to make a choice -after committing to the contents of a ballot -as to whether to cast or spoil that ballot, and if the spoil option is exercised, the contents of the ballot are publically revealed.
In this scenario, a voter who is being coerced locally would not dare violate the wishes of the coercer because the coercer might signal this approach include depositing a chit to indicate the number of positions to shift a ballot or simply pre-voting with the instruction to quietly ignore a subsequent vote.that the ballot should be spoiled and made public.
It might seem as though a voter whose coercer is not present would not face these concerns and would be free to vote without coercion.
However, the distinction disappears when a complete video recording of the voting session is possible.
A continuous recording that shows the selections made by the voter and the voter then casting the ballot with these selections makes it unnecessary to have a coercer be present in a poll site.
A coercer who can expend the resources to watch a voter through the entire period during which polling is open may have more abilities than one who can only spend a few minutes with each voter.
If so, this suggests that there is substantial benefit to election protocols which allow voters to override prior votes with new votes.Once again, however, a video recording can act as a surrogate for an active human enforcer.
In the extreme, a coerced voter can make a video recording that includes a full voting session and all subsequent actions taken until the polls are closed and the results are announced.
A continuous and uninterrupted recording of this process can serve as compelling evidence of how someone voted and that there was no opportunity to make subsequent changes.
A coercer with limited resources need not even expend the resources to view the recordings of all coerced voters; instead, the reviewing of a small random sampling of the recordings can be a sufficient deterrent to prevent large numbers of voters from voting their true preferences, and any selected recordings can be viewed at high speed to reduce the resources expended in coercion.
If the gold standard of in-person voting with the Australian ballot has lost much of its luster, how does it compare with the alternatives?Vote-by-mail is the most prevalent alternative to poll-site voting, and this form of voting is already regarded as highly susceptible to coercion.
As with poll-site voting, coercion should only be effective if initiated "before the fact", so there is little difference in that respect.
No special technology is required to coerce a postal voter, so in that respect poll-site voting is still somewhat stronger.
However, an argument can be made that a wholesale attack is now harder to mount on a postal voting system than on a poll-site voting system.
This is because the most effective postal voting attack is probably to have voters physically transfer their ballots and (signed) envelopes to the coercer, while video recordings of poll-site voting sessions can be transferred electronically and spot-checked randomly.
Although postal voters could also be coerced to provide video recordings, the process is harder to enforce because postal voting systems often allow voters to obtain multiple ballots and generally use a "first valid vote counts" strategy for dealing with multiple votes.Although it is a far less common medium, several Internet voting pilots have been conducted in recent years.
Most Internet voting systems make little or no effort to prevent coercion and are quite vulnerable.
The simplest coercive attack on these systems is usually for a coercer to collect credentials from voters.
A few Internet voting systems make valiant efforts to subvert coercion (e.g.[ Juels et al. 2010] allows voters to produce "fake" credentials that coercers cannot distinguish from real credentials), but these protocols are still susceptible to coercion begins before registration rather than before voting.
Another attack vector for Internet voting systems is malware which an attacker can even require a voter to install to monitor the voter's actions.
A large wholesale coercive attack could therefore be employed by simply instructing targeted voters to install specialized malware, and the verification process could be completely automated.
This is a vulnerability that goes well beyond those of poll-site and postal voting.It's somewhat ironic that voter choice is not beneficial in deterring coercion.
More options in the hand of a voter become more options in the hand of a coercer.
If a voter today is given a choice between voting by mail and voting in-person at a poll site that rigidly enforces rules against video recording, then a coercer can simply insist that the vote-by-mail option be exercised.
In a real sense, a multi-modal voting system is no stronger than its weakest mode.
Given the realities described above, what are the practical implications on election protocol design?There seems to be little point to adding significant complexity to election protocols in an increasingly futile attempt to defeat pre-election coercion.
While protocols should not facilitate postelection coercion by giving voters the means to disclose their votes after the fact, the ease with which ever more ubiquitous video recording technologies can defeat measures designed to prevent pre-election coercion is alarming.The metaphor of a chain being only as strong as its weakest link is apt.
While measures can be taken that effectively deter some forms of pre-election coercion, there is no justification for employing countermeasures against coercion methods which are more difficult to execute than simply pushing a "start recording" button.
Voters should not be encumbered with burdensome extra processes whose only effects are to prevent sub-optimal coercion vectors, and electoral systems which remove these barriers should not be considered inferior.Although it is not the focus of this work, it may even be worth considering whether the coercion potential of unmonitored voting systems such as vote-by-mail remains a valid argument against its use.It is more than a little surprising to think that the best defense against coercion today may not be found in an in-person voting system.
Instead, the approach that offers the most resistance to coercion may be a remote voting system using the paradigm of [Juels et al. 2010] in which voters who have successfully registered without coercion can convincingly pretend to vote according to a subsequent coercers wishes while secretly voting their own true preferences.
It may be possible to leverage this approach by allowing voters who have been coerced during registration to quietly invalidate their coerced credentials at some later opportunity and to receive new valid credentials.
This approach would, however, have similar weaknesses to the defense of allowing voters to vote multiple times with only the last vote counting -specifically, a coercer could force voters to register under coercion near the deadline and prevent any further changes until the deadline has passed.
3 Another concern is that a system which enables voters to silently replace their credentials would likely allow election officials to silently replace voters' credentials without alerting the affected voters.
Nevertheless, this direction may offer some opportunities for research into protocols which can allow voters to appear to be asceding to the demands of a coercer while taking advantage of priavte moments to express their true preferences.
Defenses against coercion and vote-selling have historically been a major component of voting system design.
While these threats remain legitimate, technologies which easily defeat pre-election coercion countermeasures are now readily available.
As such, it is now appropriate to consider the value and effectiveness of continuing to incorporate such countermeasures and to begin exploring the options that may be available for voting systems that are free from the burdens imposed by these now ineffective countermeasures.
While steps can and should be taken to prevent post-election coercion, we should also be realistic and admit to ourselves that we have no effective technical means to prevent simple, economically-scalable, remotely-enforced, pre-election coercion.Surrender is not an attractive option.
But squandering scarce resources in support of a hopeless cause is even worse.
Election systems should be designed to have the best achievable combination of properties -including integrity, privacy, reliability, and usability.
Protection from prior coercion is a crucial element of privacy, but we should be realistic about what we can and cannot achieve and not weaken other elements in an illusory attempt to protect a lost element.
Post-election audits form one of the most compelling tools for providing transparency and securing elections that use electronic technology.
Recent research has shown that ballot-level machineassisted audits [Calandrino et al. 2007;Benaloh et al. 2011] can offer significant improvements over current practice: significantly better assurance, at lower cost.
Unfortunately, the voting systems currently deployed in the US do not support ballot-level post-election audits.In this paper, we develop tools to facilitate ballot-level machine-assisted audits of elections conducted using current voting systems.
We have been working with the State of California and various California counties to pilot new methods for ballot-level machine-assisted election audits.
The approach involves re-tabulating the election using a second system that was designed from the start with support for ballot-level audits, checking that the second system selects the same winners as the official results, and then conducting an efficient ballot-level audit of the results from the second system [Lindeman et al. 2013].
This work focuses on the design of such a second system, called OpenCount, intended for this task.One might wonder, why build a new system to re-tabulate the election from scratch?
An alternative approach would be to extend deployed voting systems with the support needed for ballot-level machine-assisted audits.
However, many of the major commercial vendors are focusing their development efforts primarily on their next-generation systems rather than on upgrading deployed systems; the deployed systems are proprietary, so it is not easy for third parties to develop extensions without vendor assistance; and updates to legacy systems may require that the entire system be first certified under new EAC standards, which may be impossible, as those systems were not designed to meet the new EAC standards.
More fundamentally, many existing systems cannot be retrofitted in this way due to hardware limitations: in many deployed systems, the precinct-count optical scanners do not have the hardware capacity to record scanned images of all ballots, and there is no way to link each individual ballot to its scanned record.
Therefore, pragmatically it may be easier to deploy ballot-level audits by re-tabulating the ballots using a second system that was designed with machine-assisted auditing in mind.
That is the path we explore in this work.
Of course, our work may be of direct relevance to future generations of voting systems that wish to provide support for efficient audits.This work extends OpenCount [ Wang et al. 2012] to provide better support for ballot-level audits, based upon our experience using it to support pilots in several California counties.
This experience has helped us gain a better understanding of what is needed to allow ballot-level audits to be used in practice.
In particular, we identified two major shortcomings of the previous version of OpenCount.
First, the previous version required election officials to compile a collection of all blank ballots (one of each possible ballot style).
Due to the number of ballot types, this process proved to be laborintensive for election officials and was a hurdle to deployment.
Second, we learned that the previous version of OpenCount did not scale to large, complex elections.
When there are many ballot styles, operator data entry of contest titles, candidate names, and ballot attributes (e.g., language, precinct, tally group) became extremely tedious and time-consuming.
Each of these two is an independent barrier to being able to use OpenCount in large elections; either alone would be a showstopper, so we must solve both problems.In this paper, we show how to solve both of these two problems.
First, we develop new techniques to eliminate the need for scanned blank ballots.
This allows us to re-tabulate an election given only scans of the voted ballots (and without access to the election database from the official voting system).
Second, we develop new methods to reduce the human effort so that OpenCount will scale to large elections with many ballot types.
We implement these improvements in OpenCount.We found that these improvements are enough that we can now successfully handle large, complex elections and meet the needs of the California pilots.
We evaluate the improved OpenCount on over 560,000 ballots from 12 different elections in 11 California counties and 1 Florida county.
Our experiments show that these new methods enable order-of-magnitude speedups on medium-sized elections (∼ 30k ballots) with many ballot styles, and enable us to process large elections (∼ 120k double-sided ballots) that could not reasonably have been processed without them.This paper makes the following contributions: -We develop new methods to analyze and decode ballot styles, from scans of only the voted ballots (without needing scans of blank ballots or other external information).
We show how to rapidly identify the ballot style of each voted ballot, how to reverse-engineer the structure of contests on the ballot, and how to recognize precinct numbers and decode barcodes that identify the ballot style of each voted ballot.
-We develop new methods to reduce the amount of human effort needed to re-tabulate an election.We show how to robustly identify multiple instances of the same contest on different ballot styles (so that the operator only needs to enter in candidate names once), how to associate voting targets with contests, how to infer the bounding box of each contest robustly, and how a human operator can verify that the results of these automated methods are accurate.
-We build a tabulation system that election officials can use to conduct ballot-level audits of their elections, and that researchers can use as a basis for future research.The system is open source and is publicly available at https://code.google.com/p/opencount/.
OpenCount was inspired by the pioneering work of TEVS [Trachtenberg 2008] and Votoscope [Hursti 2005], which aim to solve the same problem.
BallotTool ] is a related system which assists an operator in retabulating a set of scanned ballots.
Our work distinguishes itself in our tight integration of computer vision techniques with focused operator interaction.
In , the authors develop a system that segments voter marks from the ballot form.
However, no attempt is made to classify the marks as filled or unfilled.
[ Xiu et al. 2009] introduces specialized classifiers that fully automate the voter intent classification task.
As future work, we intend to explore applying classifiers to further improve the ballot interpretation stages.
Document analysis is a field that considers many of the same challenges as ballot analysis.
In document analysis, researchers develop systems that automatically infer the structure of documents such as forms or articles.
The X-Y Cut algorithm [Nagy et al. 1992], shape-directed cover algorithm [Baird et al. 1990], and whitespace cover algorithm [Breuel 2002] are methods which excel at segmenting documents with white backgrounds and rectangular layouts.
See [Mao et al. 2003;Namboodiri and Jain 2007] for a survey of the document analysis field.Ballot analysis distinguishes itself in that it requires near-perfect accuracy in its interpretation of voted ballots.
Thus, any approach must be designed with this requirement in mind -towards that end, OpenCount combines automated analysis with operator interaction to accurately and efficiently process ballots.
Audit Process.
OpenCount is designed to support a transitive audit [Lindeman and Stark 2012], where one re-tabulates the election using a second system (in this case, OpenCount), checks that the second system declares the same winners as the official results, and then audits the second system.
We focus on elections conducted using paper ballots.The audit process works as follows.
After an election, election workers collect all the cast ballots and scan them all using an ordinary document scanner.
Then, OpenCount processes those scanned images to extract cast vote records (CVRs) that describe the votes present on each ballot.
Election officials tally the cast vote records, check that they declare the same winners as the official results, and then commit to the OpenCount CVRs.
Finally, election officials conduct a public, risk-limiting audit of the ballots.
During this audit process, officials repeatedly select a random ballot, pull the corresponding paper ballot, visually compare the marks on the paper ballot to the electronic CVR produced by OpenCount, and confirm that they match.
Because the paper ballots are retained in the same order they were scanned, it is possible to uniquely associate each paper ballot to its corresponding CVR, which enables the ballot-level audit.
Standard methods can be used to calculate how many ballots to examine and compute the level of confidence thus attained.For instance, this process was successfully used in Napa County to audit their June 2012 primary election [Farivar 2012].
Election officials scanned 6,809 ballots, and OpenCount was used to process those scanned ballot images.
Then, election officials used the CVRs produced by OpenCount to audit the election in a very close contest.
Napa County officials audited 559 ballots, and found that in every case the votes on the ballots exactly matched the CVRs produced by OpenCount.In this paper, we focus on the design of OpenCount and the algorithmic techniques needed to successfully analyze scanned images of ballots and produce CVRs.
OpenCount is designed to avoid relying upon election definition files from the official voting system or other external information; we would like OpenCount to rely only on scanned images, with no further external information.
The need to re-derive this information, the scale of elections, the diversity of ballot formats and voter marks, and the imperfections in scanned images make this a challenging image-processing task.Architecture.
There are four main stages to OpenCount's processing (Figure 1).
First, grouping divides the ballots into groups, where all ballots within a group share the same ballot style (that is, the same layout and same contests).
We present improvements to the grouping state that allows OpenCount to scale to larger elections.
Second, in layout annotation, a human operator assists OpenCount in identifying the structure of the ballot (location of contests, candidates, and voting targets) and enters the titles of contests and the names of candidates.
The operator only must annotate one ballot from each group.
We develop novel methods to reduce the workload of layout annotation on the operator; this is crucial to enabling us to scale.
One challenge here is to analyze the structure of the ballot robustly despite the presence of voter marks.
Third, ballot interpretation involves automated processing to identify voter marks and associate them with the corresponding contest and candidate.
Fourth, and finally, in target verification, a human operator checks OpenCount's interpretation of voter marks and inspects ambiguous or marginal marks.
The output is a cast vote record for each ballot that identifies all votes found on that ballot.
Ballot interpretation and target verification remain mostly unchanged, compared to the previous version of OpenCount [ Wang et al. 2012]; our new work primarily affects the first two stages.
A voted ballot is the ballot after a voter has marked his/her ballot and cast it.
Each ballot contains a set of contests.
A contest includes a list of candidates, with one voting target per candidate.
A voting target is an empty oval, broken arrow, or other location on the ballot where the voter should mark her ballot, if she wants to indicate a vote for the associated candidate.
A cast vote record (CVR) is a record of all selections made by the voter on a single voted ballot.The ballot style is the set of contests found on the ballot as well as the visual organization and location of these contests on the ballot.
1 For example, an English-language ballot may have the same set of contests as a Spanish-language ballot, but because their text is different, we consider them as two different ballot styles.
Similarly, two ballots may contain identical contests, but the order of candidates in the contests may not be the same; in this case, we consider them as distinct ballot styles.
Ballots may also contain a precinct number or a tally group (e.g., absentee vs. polling-place) for accumulation.Min/Max Overlay Verification.
OpenCount uses overlays [Cordero et al. 2010] to help the human operator verify the correctness of automated computations.
Overlays help the operator quickly verify that a set of images is identical, or carries the same meaning.
For instance, in Figure 3(b) the operator can immediately verify that all the images contain the word "Democratic".
Let S be a set of grayscale images of uniform dimension.
The min-overlay of S is the image S min where the intensity value at (x, y) is the lowest intensity value at (x, y) out of every image in S.
The max-overlay of S is the image S max where the intensity value at (x, y) is the highest intensity value at (x, y) out of every image in S. Intuitively, if any image in S has a black pixel at (x, y), then so does S min .
Similarly, if S max has a white pixel at (x, y), then at least one image in S does.If the min and max overlays of the images in S suggest to the operator that not all the images in S match, then the operator can choose to split S into two smaller sets.
The split operation uses the k-means algorithm [MacQueen 1967] (with k = 2) on the images in S.
The feature representation of each image is simply the pixel intensities arranged row-by-row into a vector, with the L2 norm as the distance metric.
This method works well, provided there are two image classes present that exhibit different spatial-visual distributions.
If there are more than two image classes present in the set S, the operator may need to perform several consecutive splits to further refine the results until each cluster is homogeneous.
See Figure 2(b,c) for an illustration.
In the first step of the pipeline, OpenCount separates the input set of voted ballots into groups, so that all ballots within a given group have the same ballot style.
This stage reduces the effort required in later stages: rather than asking a human operator to annotate each individual ballot, we ask the operator to annotate only one ballot from each group.
Table I summarizes the number of groups (the number of distinct styles) for a range of elections that we processed.
Notice that the number of groups is orders of magnitude smaller than the number of voted ballots.
Also, the number of groups does not necessarily scale linearly with the size of an election.
Instead, the number of groups scales with the number of possible precincts, political party affiliations, languages, and tally groups.
For instance, although Leon County has four times more voted ballots than Marin County, Leon actually has fewer groups than Marin.In the previous version of OpenCount [ Wang et al. 2012], we grouped ballots by matching each voted ballot to a corresponding blank ballot.
However, this required election officials to gather and scan one of every possible kind of blank ballot, which we discovered is very burdensome.
Therefore, we cannot rely on knowing all ballot styles a priori.
Instead, our approach is to decode the barcodes present on optical scan ballots, supplemented by additional information when necessary.
In deployed optical scan systems, the scanners rely on the presence of specialized, vendor-specific barcodes to determine ballot metadata such as the ballot style.
These barcodes can range from simple binary bit-strings to more complex encodings (Figure 7).
In most cases, the barcodes present on each ballot fully determine the ballot style, so we can group ballots by decoding the barcode and then put ballots with the same barcode into the same group.
(Section 4.2.3 describes how to handle exceptional cases where the barcode alone is not enough.)
OpenCount does not require knowledge of the semantic meaning of the barcodes; we merely need to be able to decode them to bit-strings.
That said, we have reverse-engineered the semantic meaning of most of the barcodes 2 .
For instance, several vendors incorporate a checksum in the barcode; when possible, we verify that the checksum is valid during the decoding process.OpenCount currently has built-in support for paper ballots from four major election vendors: Hart InterCivic, Premier Election Solutions (formerly Diebold Election Systems), Sequoia Voting Systems, and Election System & Software (ES&S).
It would not be difficult to add more vendors to OpenCount in the future.
To facilitate comparison of OpenCount's results to the official results, OpenCount includes support to identify the precinct number and tally group of each ballot.
This information is not always encoded in the barcode, but it is always printed in human-readable form on the ballot.
Therefore, we provide support to enable a human operator to identify these features on the ballot; OpenCount then uses this information to automatically decode these ballot attributes.
The previous system [Wang et al. 2012] did include a mechanism for this purpose.
However, there were two major shortcomings present in the previous design that we address here.
First, we extend the automated annotation process to make it more robust to variations in visual appearance, such as varying background colors and patterns.
Second, we introduce a novel approach to decoding precinct number stamps on ballots.
Decoding ballot attributes is a two-step process: attribute definition, and then (if necessary) exemplar detection.
Attribute Definition.
Within OpenCount, the operator declares a number of "ballot attributes" for each desired property (precinct number, tally group, etc.), and then defines the possible attribute values.
Additionally, the operator associates each attribute value with an image patch where this value is present in human-readable form on the ballot.Workflow.
The operator workflow is as follows.
At any given moment, there is a set of ballots that have not been fully labeled.
First, an unlabeled ballot is displayed.
The operator draws a bounding box around the location of the desired attribute (Figure 3(a)), and specifies an attribute type and value (e.g., "party: independent").
OpenCount then searches the remaining unlabeled ballots to find ballots containing a matching image patch.
Matches are identified using normalized crosscorrelation (NCC) and a fixed threshold.OpenCount then displays an overlay for all matches, so the operator can confirm that all detected matches are indeed a true match (Figure 3(b)).
This process is repeated until all ballots have a label for every defined attribute type.
Precinct-number attributes are handled separately (see Section 4.2.4 for details).
When defining an attribute, the operator indicates whether the value of the attribute is known to be consistent within each group.
If the attribute is known to be group-consistent, then OpenCount will select one ballot from each group, perform the above process, and apply the discovered labels to all ballots automatically; no further processing is needed.
Otherwise, to allow for the possibility that an attribute value may vary within a single group, OpenCount randomly selects 20% of the ballots from each group, and applies the above process to each of them; then, OpenCount applies exemplar detection and automatic annotation, detailed next.Robust Exemplar Detection.
At this point, only one image patch is defined for each attribute value.
Depending on the election, a single image patch may not be sufficient to annotate the ballots.
In Figure 4, the difference in background color (white vs. grey) overwhelms the difference in printed number ("005" vs. "006").
The image patch in Figure 4(c) is misclassified as "006" because it shares the same background as the "006" representative.More generally, we would like visual distractions such as the background style to not affect the matching process.
The previous system [Wang et al. 2012] did not have a sufficient mechanism in place to handle such variations, leading to failure cases such as Figure 4.
Thus, we introduce the following extension.
Rather than use only one image patch for each attribute value, OpenCount instead selects multiple representative image patches for each attribute value.
These representative image patches are chosen such that they capture the possible diversity present in the dataset.
The algorithm is a fixed-point iteration that takes advantage of the fact that, at this point, the software already has a set of image patches labeled with their correct attribute values (done by the operator during attribute definition).
For each attribute value, we initially choose a single image patch as the first representative patch.
The algorithm then classifies all image patches with the current set of representative image patches.
If an image patch is misclassified (i.e., a "democratic" patch was mistaken for a "republican" patch), then it is likely that this image patch contains some significant variation.
Thus, we add this image patch to the set of representatives for that attribute value, and repeat the process.To classify a new patch, we compare it to each representative and choose the attribute value whose sum-of-squared-difference (SSD) between the patch and the representative patch is minimized.
To allow for translation and rotation invariance, we first align the image patch to the representative patch prior to computing each error score.
The algorithm terminates when all image patches are classified correctly by the current set of representative image patches.
OpenCount chooses the initial representative values by selecting the image patch with the highest average pixel intensity.Automatic Attribute Annotation.
Once the operator has defined the desired attributes and representative patches, OpenCount determines the attribute values of each voted ballot.
For brevity, we refer the reader to Section 4.5 of [ Wang et al. 2012], as the core approach remains unchanged.Once the automated annotation is complete, OpenCount asks the user to verify the resulting labels using overlays (see Figure 2(b-c)).
The operator is able to correct any errors by manually relabeling any misclassified image patches.
In some cases, the ballot style may not be completely encoded within the barcodes.
For instance, the choice of language on Sequoia-style ballots affects the location of voting targets.
However, the language is not encoded in the barcodes-thus, in this case grouping by the barcodes is insufficient.
In this scenario, one may use attributes as an additional grouping criterion after the barcode-based grouping has been performed.
For instance, in the Sequoia example the operator should define a ballot attribute for the language 3 .
We added support for OpenCount to determine the precinct of each ballot, based upon the precinct number printed on the ballot.
The previous version of OpenCount used the attribute decoding process described above for this purpose.
However, while processing ballots from the June 2012 primary, we found that this approach was inadequate: the number of different precincts is large enough that this imposes an overwhelming burden on the operator.
Additionally, without precinct number recognition we would require one attribute per precinct; since grouping runs linear in the number of different groups, this becomes prohibitively slow.Therefore, we designed an alternative method for decoding precinct numbers.
After experimenting with off-the-shelf OCR software, we found it was not accurate enough for our purposes.
Instead, The overlay of all matches is presented to the user.
After splitting once, we obtain two groups, shown stacked vertically.
The top overlay shows that all digits in that group are clearly a "0".
In contrast, the bottom overlay reveals that the group contains some mismatches, e.g., "6" or "8".
(c) The accepted matches are labeled with their value ("0").
we designed a novel solution to this problem, which works by recognizing each individual digit and taking advantage of the fact that all digits within the same election are printed in the same font.
The algorithm works in two steps: digit exemplar selection, and digit parsing.Digit Exemplar Selection.
In this step, we obtain an example of each digit (0-9) directly from the ballot images themselves.
Once OpenCount knows what each digit looks like for this particular election, we can decode a precinct number by visually comparing the digits in the precinct region to its set of example digits.To obtain examples of each digit, OpenCount displays all the precinct numbers in a grid 4 , one patch from each group.
See Figure 5(a).
The operator selects an unlabeled digit and draws a bounding box around that digit, and enters the correct digit value (e.g., "0").
OpenCount then uses template matching across all precinct patches to find all matches for the selected digit.
Any matches whose NCC (normalized cross-correlation) score exceeds a fixed threshold is retained as a potential candidate, and the operator confirms all candidate matches using an overlay verification step ( Figure 5(b)).
After the verification is complete, the operator-accepted matches can be labeled with their value (as shown in Figure 5(c)).
The task is finished once all digits in all precinct patches have been labeled.
To account for possible background pattern variations, OpenCount employs the same robust exemplar patch detection technique from Section 4.2.2 for each digit.Digit Parsing.
Once OpenCount has example image patches for each digit, it can begin to interpret the precinct patches (i.e., given an image containing a precinct number, recover the decimal string).
Intuitively, each unknown digit in the precinct patch could be decoded by comparing it against all exemplars to find its closest match.
However, we would like our approach to not require an initial segmentation of the unknown precinct patch into its individual digits.
Ballots may not be scanned at very high resolution, and coupled with scanner noise, segmentation algorithms are likely to output incorrect results.
This is exacerbated by the fact that precinct stamps are often printed in a small font.
Instead, we implemented a dynamic programming algorithm to simultaneously identify the location of all digits in the unknown patch and find each digit's best match among the exemplars.The core of our approach is a scoring algorithm that compares a representative digit against a particular precinct number through a combination of the individual digit match confidence scores and spatial relationships between adjacent pairs of digits.
More formally, let L = (l 1 , ..., l n ) represent a configuration of an n-digit precinct number on a ballot where l i is the (x, y) coordinate of the i th digit.
Let m(l (c) i ) be the match cost of a digit, c at location l i .
We compute this as the NCC score between the template image of that digit and the ballot at location l i .
Now let M(l i ) = max c l (c) i store the best match score of all digits at a given location and Q(l i ) = argmax c l (c) i store the identities of the digits at those locations.
Finally, let d(l i , l j ) represent the pairwise penalty of two adjacent digits placed at l i and l j .
In our case, the ideal location for l j given l i is to be one character's width away on the x-axis while being on the same y-axis.
We set d(l i , l j ) to be a quadratic cost for deviations from the ideal location.
Our algorithm solves for the optimal configuration L * , using the function:L * = argmin L   n ∑ i=1 M i (l i ) + ∑ (v i ,v j )∈E d i j (l i , l j )  (1)The cost of any configuration of digits L is the sum of the cost of their individual match scores and sum of pairwise spatial costs.
Our formulation draws from the Pictorial Structures work of [Fischler and Elschlager 1973;Felzenszwalb and Huttenlocher 2005] and a solution can be found efficiently using dynamic programming.
This algorithm allows us to efficiently and accurately decode precinct numbers on all ballots, using the exemplars selected by the operator in the previous stage.
Once the precinct decoding is complete, OpenCount asks the user to verify the labeling results via overlay verification.
The user can correct any misclassified digits here, if necessary.
After OpenCount has grouped the ballots, the operator must then annotate the layout of one ballot from each group.
In the previous version of OpenCount [ Wang et al. 2012], annotation of contests and candidates in very large elections required a lot of operator effort: directly proportional to the number of contests per ballot, times the number of different ballot styles.
We designed several new methods to greatly reduce the workload on the operator in complex elections.Detecting Voting Targets.
OpenCount assists the operator in identifying the location of all voting targets in every group.
When blank ballots are available, this is easy: the operator can identify one example of an empty voting target, and the system can find all matches on all blank ballots.
Since the blank ballots do not have any voter marks, all matches should be clean.
However, when we do not have blank ballots, more sophisticated methods are necessary.
Our improved procedure works as follows.
For each group, one ballot is arbitrarily selected and displayed to the operator.
The operator then draws a bounding box around one of the voting targets.
Once a voting target is selected, OpenCount automatically tries to detect as many matching voting targets as possible using template matching on all remaining unannotated groups.
Any match whose NCC score is above a fixed threshold is accepted as a candidate voting target.
To prevent multiple overlapping matches, once a match is processed, all other NCC scores within a fixed region around the match are suppressed.
We apply smoothing with a Gaussian kernel to the template and ballot images prior to template matching to improve detection rates.OpenCount applies an additional technique to further reduce operator effort.
We select N representative ballots from each group, template match against all representatives, and union the results together 5 .
This is intended to solve the problem that voter marks often interfere with the template matching search.
For instance, if the operator draws a bounding box around an empty voting target, filled targets will not be identified as matches during the template matching.
However, the same voting target will be present on the other N − 1 representatives in that group, and it is likely that it will be empty in at least one of these cases; thus the union trick allows us to detect the location of that voting target.
We set N = 5, which offers a good balance between convenience and performance.Detecting Contest Bounding Boxes.
We implement a method to identify the "bounding boxes" of contests on a ballot-a rectangular region that surrounds all of the voting targets in a contest.
These bounding boxes help recognize which voting targets belong to the same contest, which is used for tabulation purposes.
The contest bounding boxes also enable us to identify redundant contests by performing pair-wise comparisons between the set of detected contests; this enables a major reduction in the amount of data entry required.
The previous version of OpenCount implemented a more naive approach.
Instead of attempting to identify the actual contest bounding box, voting targets were instead grouped together by distance.
However, as we experimented with large elections with many ballot styles, we discovered that this naive heuristic was both incorrect and could not find a box surrounding all candidate names.We developed a new algorithm which is much more accurate, and also provides the full bounding boxes.
We find it only makes errors the ballot has significant stray voter marks, and in those cases we provide a mechanism to select an alternate ballot in the same group without such marks.
Our algorithm takes advantage of the fact that, on all ballot styles we have encountered, each contest is at least partially surrounded by horizontal and/or vertical lines that demarcate it from other contests.First, OpenCount identifies all vertical and horizontal lines on the ballot.
This is done by scanning over the ballot for pixels darker than some threshold, and attempting to identify if this is part of a long vertical or horizontal line segment.
Only segments of a large enough size are retained.
Line segments are identified by continuous segments of pixels darker than some threshold.We then reduce all the scattered line segments through several intermediate steps.
First, line segments are joined together if they extend in the same direction and are overlapping.
Second, line segments are removed if they do not intersect with any perpendicular segments.
Third, segments are removed if no voting target is located in the area it could possibly be extended to.Next, we process the ballot to determine if there is some constant C where, if all lines were extended by a factor of C, significantly more intersections are found.
This allows for cases where vertical and/or horizontal lines are present on the ballot, but do not fully intersect each other, as happens on several styles.Finally, OpenCount searches over all candidate rectangles that can be formed by these lines (from smallest rectangle to largest), looking for rectangles that contain voting targets.
When a rectangle does contain at least one voting target, all of the targets in its interior are removed and the process is repeated.
For some vendors, it is necessary to combine multiple bounding boxes together to form the final set of bounding boxes; in these ballot styles, contests are finally merged.
For example, Figure 6 shows that each contest is contained within its own bounding box in the second image, but in the third image many are merged together to form the correct contest bounding boxes.Once OpenCount infers all bounding boxes, it presents them to the operator, who can manually correct any errors.
OpenCount can optionally detect bounding boxes on the other four representative ballots and warn the operator if the bounding boxes are not identical on all five.Contest Data Entry.
The final step in ballot annotation is to label all detected contests with the contest title and the candidate names.
This is crucial information to allow OpenCount to output human-readable election results.
In principle, this is not a difficult task-one can simply ask the operator to enter the relevant text on a representative ballot from each group.
In fact, this is what was done in the previous version of OpenCount.However, in many elections there are several hundred different groups, and manually annotating every contest on every group would take many hours of manual effort.
To address this challenge, we developed new methods to detect contests that are duplicates of each other.
While there may be hundreds of groups, each having several contests, there are typically only a few distinct contests in the entire election.
If duplicates can be detected, the operator only needs to label one instance of each contest.
In practice, we find that this speeds up the contest data entry process from between a factor of ten to a hundred for large elections, not counting computation time.Unfortunately, detecting duplicate contests is a difficult task.
We experimented with many strategies for recognizing when two contests are the same by comparing them as images, but all failed.
There are three key challenges.
First, contests that are semantically equivalent may not necessarily be visually identical.
Examples of such visual discrepancies include varying image dimensions, text lines wrapped at different locations, and inconsistent spacing between the words in candidate names.
Second, the order of candidates on a given contest may be different on two different instances, due to ballot rotation.
And third, some contests do not fit on a single column of a ballot, but continue onto the next column.We resolve the first challenge by using an off-the-shelf Optical Character Recognition (OCR) software as a preprocessor to extract the text from the contest images 6 .
We extract the title and the candidate names independently.
To compare the similarity of two contests, we then use the Levenshtein (edit) distance [Levenshtein 1966] between the extracted text of the two contests.
By comparing the OCR outputs between two contests, rather than the contest images themselves, we remain invariant to the visual confounding factors mentioned previously.
Crucially, this approach allows us to tolerate inaccuracies in the OCR output.
For example, if the OCR were only accurate on 50% of the characters, we would expect the Levenshtein distance to be 25% smaller for two identical contests than for two different contests (of similar length).
In practice, we found that Tesseract makes many errors, but it is still over 90% accurate on most ballot styles and languages.Solving the second challenge requires more work.
At a high level, whenever we test a pair of contests for equivalence, we search over all possible rotations of the candidate names and find the best match.
For all elections we are aware of, candidate names are not permuted arbitrarily.
Instead, they are simply rotated some number of positions, with one modification: the write-in candidate(s) always appear at the end.
Therefore, our algorithm takes advantage of this fact.
Once we have extracted both the contest title and the candidate names for each voting target, we attempt to determine (a) the number of write-in candidates and (b) the rotation amount.
In particular, we search over all possible number of write-ins, and all possible rotations.
We then treat two contests as duplicates if they have both the same number of write-in contests, and if they have a small Levenshtein distance between the names of corresponding candidates.We solve the third challenge by letting the operator mark contests that span multiple columns while labeling the voted ballots: if the operator finds such a contest while entering text on the ballots, she clicks a button marking it as such, and continues on.
7 OpenCount then performs another search over all consecutive pair of contests to attempt to identify other contests that also are split across two bounding boxes by comparing their similarity against the pair the operator marked.We implement several optimizations to improve performance.
First, contests are only compared if they have the same language and same number of targets; and second, we sort candidates by length and perform an initial linear scan where we compare consecutive contests, to detect some duplicates quickly.
These two optimizations typically reduce computation time by a factor of a hundred on large elections.
Finally, the we present operator with an overlay of the contests.
We align candidates independently, and merge them together to form a single overlay.
The user then verifies that the resulting overlays indeed correspond to the same contest.
See Figure 8 (Right) for an example overlay.
Once the operator has annotated a representative of each group, OpenCount uses this information to interpret the remaining ballots.
We did not need to make major improvements or changes to this stage from the previous version of OpenCount [ Wang et al. 2012], though we did take the opportunity to improve performance in several places.
For convenience, we summarize this stage: -Extract voting targets.
In each group, OpenCount takes a representative and globally aligns all other ballot to it.
OpenCount then locally aligns each voting target to the corresponding voting target on the representative, and extracts it.
The current version runs on average three times faster.
-Classify voting targets.
OpenCount then presents the operator with a grid of targets sorted by average intensity, who then identifies which targets are filled.
We added the capability for the operator to set filters to only show overvotes and undervotes or only targets from a given contest, or to run a second classifier over the voting targets and display only disagreements.
-Handle quarantined ballots.
Finally, the operator handles all ballots that were quarantined.The operator manually indicates the votes for each contest, as well as the ballot attribute values.
Partial information about each ballot is automatically populated when possible.
For instance, if a ballot was quarantined after contests were inferred, this information is automatically filled.
The previous version of OpenCount did not have this feature, making it much more labor-intensive.
-Generate results.
OpenCount generates CVRs and cumulative vote tallies.
Each CVR specifies the candidates that the voter voted for.
Overvotes and undervotes are identified as such.
The cumulative vote tallies show the vote totals for each candidate in each contest.
These totals are further broken down by precinct and tally group if those attributes are available, which assists in comparing with the official results at a finer granularity.
We ran OpenCount on the 12 elections listed in Table I, and also ran the previous version of OpenCount [ Wang et al. 2012] on a subset of the elections.
We timed how long each took, on a six-core machine Intel i7-3930K processor with 16GB of RAM.
Table II records the results.
Different operators ran different elections, so comparisons on timing statistics from election to election may not be meaningful.
However, whenever we ran both versions of OpenCount on an election, the same operator ran both versions.
On elections where both versions of OpenCount were run, the results between election runs match on ≥ 99.9% of ballots.
8 The only differences were Table II.
Election timing data with OpenCount.
Steps that require operator interaction are labeled with (H), and steps that only perform computation are labeled with (C).
The second column identifies the version of OpenCount used; the 2013 version contains the improvements described in this paper, whereas the 2012 version does not.
Times are rounded to the nearest minute, except for the "Total" column.
Entries tagged with a * are extrapolated (see text for details).
Version almost always the result of the operator interpreting ambiguous marks differently (i.e., a mark that may either be caused by an erasure, or may be a lightly-filled in mark).
OpenCount developers processed each elections.
We also invited Tom Stanionis, an election official from Yolo county, to evaluate the OpenCount software.
Mr. Stanionis was able to successfully process an election subset without any significant intervention from the developer conducting the evaluation.
We gathered valuable feedback and constructive criticism about the software from a usability standpoint.
We analyzed five special elections from 2011 (the same ones evaluated in [Wang et al. 2012]): Stanislaus, Merced, Ventura, Alameda, and San Luis Obispo (SLO).
All of these have only a few contests.
Three have only a single ballot style.
Alameda has 8 ballot styles, but is the smallest election we analyzed, with only 1,374 ballots.
SLO has 27 ballot styles, but all styles contain the same two contests, differing only in precinct and tally group.The results are given in Table I. Because these elections are so small and contain so few contests and so few ballot styles, the 2011 elections do not stress-test the ability of OpenCount to handle complex elections with many ballot styles.
For instance, Alameda shows the least benefit from our improvements: with so few ballots, very few of the additions have an impact on total running time.
Instead, the total time spent is dominated by initial setup.
As it happens, many ballots in the Alameda election were quarantined because the scanned ballot was missing the top portion of the ballot, which included the barcode, see Table III for full quarantine statistics.
We also analyzed ballots from the June 2012 primary in five counties.
These elections were more complex.
As a primary election, they contained many more ballot styles.
Madera was by far the smallest, with only one ballot style, and we encountered no difficulties.Napa.
Napa had 28 ballot styles and we were able to process all 6,809 ballots using our improved version of OpenCount without incident.
The previous version of OpenCount made serious errors during target extraction and extracted the wrong regions on nearly 50% of ballots.
On ballots where targets were extracted correctly, the two versions matched with over 99.9% accuracy.
On the remaining 50%, we randomly sampled 20 ballots and, in every case, the current version of the software was completely correct, and the previous version was wrong.
Our improvements led to a modest (2.8×) speedup; however, with so few ballot styles, many of our improvements do not take effect.Marin.
The Marin election had 398 ballot styles, so it was a good stress test of our improvements to reduce operator effort.
The improvements were crucial to our ability to successfully analyze this election.
However, target extraction failed for 115 ballots, due to poor image alignment, and these ballots had to be flagged for manual processing.
This dominated the time it took for us to process the Marin ballots.Santa Cruz.
Santa Cruz had fewer ballot styles, which made processing go quickly.
However, verifying the interpretation of marks was made more challenging because Santa Cruz uses a Sequoia complete-the-arrow style ballot, and OpenCount's visualization tool is not as effective for these ballots.
This is a good opportunity for further improvements.
Also, target extraction failed for 84 ballots, which had to be flagged for manually processing.
In each case, the initial image alignment between the ballot and the reference image was incorrect, causing a wildly inaccurate alignment to occur.
See Section 6.2 for additional discussion about these alignment issues.Yolo.
Yolo was our second most complex and third-largest election.
The time to label contests includes the 13 minutes of computation OpenCount spent detecting equivalent contests, which massively reduced the amount of data-entry required, from 4,603 contests to fewer than 50.
The absence of blank ballots made it significantly more challenging to identify all voting targets: this task took two times longer than on the previous version, when blank ballots were available.
This is due both to the increase in the number of groups-there are 117 different blank ballots, but this increases to 623 groups when we do not have blank ballots-and to the increase in operator workload due to the presence of voter marks-the operator must repeatedly identify empty voting targets, to ensure all are found.
As an experiment, we ran the ballot annotation process of the current version of OpenCount on the 117 blank ballots, and found that it ran six times faster.We did not complete grouping verification in its entirety on the previous version of OpenCount.
After finishing 5% of grouping verification (in two hours), we extrapolated that grouping verification would take about 40 hours.
We used data from the current version of OpenCount to fill in the remaining data.Leon.
With 124,200 ballots, the November 2008 general election in Leon County, Florida was our second largest election processed.
We only ran Leon on the most recent version of OpenCount; processing it with the previous version would have taken an unreasonable amount of time.
The contest labeling step of Leon took much longer than that of Yolo, because Leon had several contests of the form "District court of appeals.
Shall Justice be retained in office" for each of five different justices.
This caused the contest equivalence class computation to erroneously infer that all of these contests were identical; we had to reject and manually label these contests, which took extra time.Orange.
Finally, we processed the Orange county June 2012 Presidential Primary Election, which consisted of 294,402 voted ballots with a variable number of sides per ballot, ranging from one to three.
This election has as many ballots as all other elections combined.
Similar to Leon County, we only processed the ballots with the most recent version of OpenCount.This election dataset posed several significant challenges.
First, the scan quality of these images is noticeably poorer than that of any of the other elections.
Rather than rescanning the paper ballots with commercial scanners to obtain high-quality image scans, these images were output directly from the Hart voting systems.
This is both good and bad; while no additional scanning effort was necessary, we had to modify OpenCount to handle much more challenging images due to scanning conditions outside of our control.
Additionally, the images are binary images, thresholded by the Hart system, which further degraded the image quality through the loss of information.
Second, the complexity of the election is by far the greatest: there are 1,839 distinct ballot styles 9 .
While completing the "Target Check" stage, we discovered that the target sorting metric currently used is inadequate for elections of this size, and requires the operator to inspect an overwhelming number of voting targets.
The average-intensity heuristic used for sorting targets breaks down when voter marks are small in comparison to the voting target itself.
Image noise then dominates the sorting metric, resulting in empty voting targets being mixed with filled-in voting targets, requiring many hours of manual corrections.
It is worth noting that these sparsely filled-in voting targets are typically cases where the voter drew in an "X" or a line to indicate his or her vote.
Improving this step is a focus for future work, and may draw upon ideas from the style-based mark classifier of [Xiu et al. 2009].
Thus, we completed a small portion of the "Target Check" stage and extrapolated the total time required.
The timing data for the "Label Contests" stage was similarly extrapolated.Interestingly, Orange County had the lowest percentage of quarantined ballots (Table III).
One question we must consider is how well OpenCount will generalize.
For this system to be useful, it must minimize the restrictive assumptions it makes on specific ballot details.
We consider the major assumptions that OpenCount makes in this section.Consequences and Relaxation.
OpenCount is currently able to support optical scan ballots from Diebold (Premier), ES&S, Hart, and Sequoia systems, which accounts for the overwhelming majority of opscan ballots in the US.
Of the requirements listed above, the most stringent is the requirement that the ballot contain a barcode that can be used for grouping.
Fortunately, all ballots that we have encountered to date meet this requirement.
To relax this requirement, one could imagine applying algorithms that group ballots on visual appearance.
However, we have not investigated the challenges associated with doing so.
Finally, while OpenCount currently does not support voting schemes such as straight-party voting or fusion voting, it would be simple to modify the logic to accommodate such voting schemes.
In several stages of the pipeline, ballots are aligned to a representative ballot.
The image alignment method used in OpenCount assumes a rigid transformation model, which allows translation and rotation variation.
The simpler rigid model performed better than more complex models such as the affine model, as the rigid model has fewer parameters to solve for, typically leading to higherquality solutions.
Additionally, in practice, almost all images can be aligned with only translations and rotations, and do not require other affine warps (scaling, shearing, etc.).
Our alignment scheme is able to tolerate a moderate amount of non-rigid warping, due to the fact that it performs two alignment steps: a coarse "global" alignment of the entire image, followed by a finer "local" alignment applied to small regions of the image.
Both alignments still use rigid transformations.
If an image contains non-uniform warping (e.g., the bottom-half of the image is stretched/skewed more than the top), then no precise global alignment will exist between this warped image and its reference image.
However, a good local alignment can often still be recovered, allowing our scheme to tolerate a moderate amount of non-uniform warping.
If ballots contain too much non-rigid warping, then mis-alignment errors will cause issues during target extraction.
Such issues affected 0.2% of Santa Cruz ballots, as mentioned in Section 5.3.
The improvements made to the OpenCount system in this paper have enabled the processing of significantly larger and more complex elections.
The previous system was not able to reasonably process the Yolo county election, let alone the Leon or Orange datasets.
The current proposed system, on the other hand, is able to process all three without trouble.However, it remains to be seen how the system will scale to even larger elections.
For instance, about 3.2 million ballots were cast in November 2012 in Los Angeles county [LA-Registrar 2012].
This is roughly 11× larger than the Orange county election.
Future work is needed to investigate whether OpenCount is able to efficiently handle elections of that magnitude.
We have introduced several significant improvements to the original OpenCount system that enables OpenCount to scale to significantly larger elections, and process them an order of magnitude faster.
The new system does not require the collection of blank ballots, which reduces the barrier on election officials; we also greatly reduce the amount of data entry required, which speeds the re-tabulation process.
These improvements enabled OpenCount to successfully support audit pilots in 11 California counties and advance the state of the art in ballot image analysis.
We thank the California Secretary of State's office and election officials at Stanislaus, Merced, Ventura, Alameda, San Luis Obispo, Madera, Marin, Napa, Santa Cruz, Yolo, Orange, and Leon counties for sharing scanned ballots, and Clear Ballot for their assistance with obtaining ballot scans.
This research would not have been possible without their generous assistance.
We thank Philip Stark for helpful guidance and Tom Stanionis for providing feedback on OpenCount.
x
