Today's Web services-such as Google, Amazon, and Facebook-leverage user data for varied purposes, including personalizing recommendations, targeting advertisements, and adjusting prices.
At present, users have little insight into how their data is being used.
Hence, they cannot make informed choices about the services they choose.
To increase transparency, we developed XRay, the first fine-grained, robust, and scalable personal data tracking system for the Web.
XRay predicts which data in an arbitrary Web account (such as emails, searches, or viewed products) is being used to target which outputs (such as ads, recommended products, or prices).
XRay's core functions are service agnostic and easy to instantiate for new services, and they can track data within and across services.
To make predictions independent of the audited service, XRay relies on the following insight: by comparing outputs from different accounts with similar, but not identical, subsets of data, one can pinpoint targeting through correlation.
We show both theoretically, and through experiments on Gmail, Amazon, and YouTube, that XRay achieves high precision and recall by correlating data from a surprisingly small number of extra accounts.
We live in a "big data" world.
Staggering amounts of personal data -our as locations, search histories, emails, posts, and photos -are constantly collected and analyzed by Google, Amazon, Facebook, and a myriad of other Web services.
This presents rich opportunities for marshaling big data to improve daily life and social well-being.
For example, personal data improves the usability of applications by letting them predict and seamlessly adapt to future user needs and preferences.
It improves business revenues by enabling effective product placement and targeted advertisements.
Twitter data has been successfully applied to public health problems [36], crime prevention [44], and emergency response [22].
These beneficial uses have generated a big data frenzy, with Web services aggressively pursuing new ways to acquire and commercialize it.Despite its innovative potential, the personal data frenzy has transformed the Web into an opaque and privacy-insensitive environment.
Web services accumulate data, exploit it for varied and undisclosed purposes, retain it for extended periods of time, and possibly share it with others -all without the data owner's knowledge or consent.
Who has what data, and for what purposes is it used?
Are the uses in the data owners' best interests?
Does the service adhere to its own privacy policy?
How long is data used after its owner deletes it?
Who shares data with whom?At present, users lack answers to these questions, and investigators (such as FTC agents, journalists, or researchers) lack robust tools to track data in the everchanging Web to provide the answers.
Left unchecked, the exciting potential of big data threatens to become a breeding ground for data abuses, privacy vulnerabilities, and unfair or deceptive business practices.
Examples of such practices have begun to surface.
In a recent incident, Google was found to have used institutional emails from ad-free Google Apps for Education to target ads in users' personal accounts [18,37].
MySpace was found to have violated its privacy policy by leaking personally identifiable information to advertisers [25].
Several consumer sites, such as Orbitz and Staples, were found to have adjusted their product pricing based on user location [29,43].
And Facebook's 2010 ad targeting was shown to be vulnerable to micro-targeted ads specially crafted to reveal a user's private profile data [23].
To increase transparency and provide checks and balances on data abuse, we argue that new, robust, and versatile tools are needed to effectively track the use of personal data on the Web.
Tracking data in a controlled environment, such as a modified operating system, language, or runtime, is an old problem with a well-known solution: taint tracking systems [12,16,7,48].
However, is it possible to track data in an uncontrolled environment, such as the Web?
Can robust, generic mechanisms assist in doing so?
What kinds of data uses are trackable and what are not?
How would the mechanisms scale with the amount of data being tracked?As a first step toward answering these questions, we built XRay, a personal data tracking system for the Web.
XRay correlates designated data inputs (be they emails, searches, or visited products) with data outputs results (such as ads, recommended products, or prices).
Its correlation mechanism is service agnostic and easy to instantiate, and it can track data use within and across services.
For example, it lets a data owners track how their emails, Google+, and YouTube activities are used to target ads in Gmail.At its core, XRay relies on a differential correlation mechanism that pinpoints targeting by comparing outputs in different accounts with similar, but not identical, subsets of data inputs.
To do so, it associates with every personal account a number of shadow accounts, each of which contains different data subsets.
The correlation mechanism uses a simple Bayesian model to compute and rank scores for every data input that may have triggered a specific output.
Intuitively, if an ad were seen in many accounts that share a certain email, and never in accounts that lack that email, then the email is likely to be responsible for a characteristic that triggers the ad.
The email's score for that ad would therefore be high.
Conversely, if the ad were seen rarely in accounts with or lacking that email, that email's score for this ad would be low.Constructing a practical auditing system around differential correlation raises significant challenges.
Chief among them is scalability with the number of data items.
Theoretically, XRay requires a shadow account for each combination of data inputs to accurately pinpoint correlation.
That would suggest an exponential number of accounts!
Upon closer examination, however, we find that a few realistic assumptions and novel mechanisms let XRay reach high precision and recall with only a logarithmic number of accounts in number of data inputs.
We deem this a major new result for the science of tracking data-targeting on the Web.We built an XRay prototype and used it to correlate Gmail ads, Amazon product recommendations, and YouTube video suggestions to user emails, wish lists, and previously watched videos, respectively.
While Amazon and YouTube provide detailed explanations of their targeting, Gmail does not, so we manually validated associations.
For all cases, XRay achieved 80-90% precision and recall.
Moreover, we integrated our Gmail and YouTube prototypes so we could track cross-service ad targeting.
Although several prior measurement studies [10,47,21,20,31] used methodologies akin to differential correlation, we believe we are the first to build a generic, service agnostic, and scalable tool based on it.
Overall, we make the following contributions: 1.
The first general, versatile, and open system to track arbitrary personal Web data use by uncontrolled services.
The code is available from our Web page https://xray.cs.columbia.edu/.2.
The first in-depth exploration into the scalability challenges of tracking personal data on the Web.
3.
The design and implementation of robust mechanisms to address scaling, including data matching.
4.
System instantiation to track data on three services (Gmail, Amazon, YouTube) and across services (YouTube to Gmail).
5.
An evaluation of our system's precision and recall on Gmail, Amazon, and YouTube.
We show that XRay is accurate and scalable.
Further, it reveals intriguing practices now in use by Web services and advertisers.
This paper lays the algorithmic foundations for a new generation of scalable, robust, and versatile tools to lift the curtain on how personal data is being targeted.
We underscore the need for such tools by describing potential usage scenarios inspired by real-life examples ( §2.1).
We do this not to point fingers at specific service providers; rather, we aim to show the many situations where transparency tools would be valuable for endusers and auditors alike.
We conclude this section by briefly analyzing how current approaches fail to address these usage scenarios ( §2.2).
Scenario 1: Why This Ad?
Ann often uses her Gmail ads to discover new retail offerings.
Recently, she discussed her ad-clicking practices with her friend Tom, a computer security expert.
Tom warned her about potential privacy implications of clicking on ads without knowing what data they target.
For example, if she clicks on an ad targeting the keyword "gay" and then authenticates to purchase something from that vendor, she is unwittingly volunteering potentially sensitive information to the vendor.
Tom tells Ann about two options to protect her privacy.
She can either disable the ads altogether (using a system like AdBlock [1]), or install the XRay Gmail plugin to uncover targeting against her data.
Unwilling to give up the convenience of ads, Ann chooses the latter.
XRay clearly annotates the ads in the Gmail UI with their target email or combination, if any.
Ann now inspects this targeting before clicking on an ad and avoids clicking if highly sensitive emails are being targeted.
Scenario 2: They're Targeting What?
Bob, an FTC investigator, uses the XRay Gmail plugin for a different purpose: to study sensitive-data targeting practices by advertisers.
He suspects a potentially unfair practice whereby companies use Google's ad network to collect sensitive information about their customers.
Therefore, Bob creates a number of emails containing keywords such as "cancer," "AIDS," "bankruptcy," and "unemployment.
To investigate scientifically whether this omission represents a shift in implemented policy, she obtains institutional accounts, connects them to personal accounts, and uses XRay to detect the correlation between emails in institutional accounts and ads in corresponding personal accounts.
Finding a strong correlation, Carla writes an article to expose the policy change and its implications.
Scenario 4: Does Delete Mean Delete?
Dan, a CS researcher, has seen the latest news that Snapchat, an ephemeral-image sharing Website, does not destroy users' images after the requested timeout but instead just unlinks them [41].
He wonders whether the reasons for this are purely technical as the company has declared (e.g., flash wearing levels, undelete support, spam filtering) [39,38] or whether these photos, or metadata drawn from them, are mined to target ads or other products on the Website.
The answer will influence his decision about whether to continue using the service.
Dan instantiates XRay to track the correlation between his expired Snapchat photos and ads.
The preceding scenarios illustrate the importance of transparency in protecting privacy across a range of use cases.
We need robust, generic auditing tools to track the use of personal data at fine granularity (e.g., individual emails, photos) within and across arbitrary Web services.
At present, no such tools exist, and the science of tracking the use of personal Web data at a fine grain is largely non-existent.
Existing approaches can be broadly classified in two categories: protection tools, which prevent Web services' acquisition or use of personal data, and (2) auditing tools, which uncover Web services' acquisition or use of personal data.
We discuss these approaches next; further related work is in §9.
Protection Tools.
A variety of protection tools exist [11,35,1,49].
For example, Ann could disable ads using an ad blocker [1].
Alternatively, she could encrypt her emails, particularly the sensitive ones, to prevent Google from using them to target ads.
Dan could use a self-destructing data system, such as Vanish [14], to ensure the ephemerality of his Snapchat photos.While we encourage the use of protection tools, they impose difficult tradeoffs that make them inapplicable in many cases.
If Ann blocks all her ads, she cannot benefit from those she might find useful; if she encrypts all of her emails, she cannot search them; if she encrypts only her sensitive emails, she cannot protect any sensitive emails she neglected to encrypt in advance.
Similarly, if Dan encrypts his Snapchat photos, sharing them becomes more difficult.
While more sophisticated protection systems address certain limitations (e.g., searchable [5], homomorphic [15,33], and attribute-based encryption [19], or privacy-preserving advertising [42,13]), they are generally heavyweight [15], difficult to use [45], or require major service-side changes [15,42,13].
Auditing Tools.
Given the limitations of protection tools, transparency is gaining increased attention [47,12,21].
If protecting data proves too cumbersome, limiting, or unsupportive of business needs, then users should at least be able to know: (1) who is handling their data?
, and (2) what is it being used for?Several tools developed in recent years partially address the first question by revealing where personal data flows from a local device [34,12,8].
TaintDroid [12] uses taint tracking to detect leakage of personal data from a mobile application to a service or third-party backend.
ShareMeNot [34] and Mozilla's Lightbeam Firefox add-on [27] identify third parties that are observing user activities across the Web.
These systems track personal data -such as location, sensor data, Web searches, or visited sites -until it leaves the user's device.
Once the data is uploaded to Web services, it can be used or sold without a trace.
In contrast, XRay's tracking just begins: we aim to tell users how services use their data once they have it.Several new tools and personalization measurement studies partially address the second question: what data is being used for [10,47,21,20,31].
In general, all existing tools are highly specialized, focusing on specific input types, outputs, or services.
No general, principled foundation for data use auditing exists, that can be applied effectively to many services, a primary motivation for this our work.
For example, Bobble [47] reveals search result personalization based on user location (e.g., IP) and search history.
Moreover, existing tools aim to discover only whether certain types of user inputs -such as search history, browsing history, IP, etc. -influence the output.
None pinpoints at fine grain which specific input -which search query, which visited site, or which viewed product -or combination of inputs explain which output.
XRay, whose goals we describe next, aims to do just that.
Our overarching goal is to develop the core abstractions and mechanisms for tracking data within and across arbitrary Web sites.
After describing specific goals ( §3.1), we narrow our scope with a set of simplifying assumptions regarding the data uses that XRay is designed to audit ( §3.2) and the threats it addresses ( §3.3).
Three specific goals have guided XRay's design:Goal 1: Fine-Grained and Accurate Data Tracking.
Detect which specific data inputs (e.g., emails) have likely triggered a particular output (e.g., an ad).
While coarse-grained data use information (such as Gmail's typical statement, "This ad is based on emails from your mailbox.")
may suffice at times, knowing the specifics can be revelatory, particularly when the input is highly sensitive and aggressively targeted.Goal 2: Scalability.
Make it practical to track significant amounts of data (e.g., past month's emails).
We aim to support the tracking of hundreds of inputs with reasonable costs in terms of shadow accounts.
These accounts are generally scarce resource since their creation is being constrained by Web services.
While we assume that users and auditors can obtain some accounts on the Web services they audit (e.g., a couple dozen), we strive to minimize the number required for accurate and finegrained data tracking.Goal 3: Extensibility, Generality, and Self-Tuning.
Make XRay generic and easy to instantiate for many services and input/output types.
Instantiating XRay to track data on new sites should be simple, although it may require some service-specific implementation of input/output monitoring.
However, XRay's correlation machinery -the conceptually challenging part of a scalable auditing tool -should be turn key and require no manual tuning.
These goals may appear unsurmountable.
An extremely heterogeneous environment, the Web has perhaps as many data uses as services.
Moreover, data mining algorithms can be complex and proprietary.
How can we abstract away this diversity and complexity to design robust and generic building blocks for scalable data associations (email→ad, viewed→recommend) one or more Web services data inputs (emails, searches, viewed products) targeted outputs tracking?
Fortunately, we find that certain popular classes of Web data uses lend themselves to principled abstractions that facilitate scalable tracking.
Figure 1 shows XRay's simplified view of Web services.
Services, and networks of services that exchange user data, are black boxes that receive personal data inputs from users -such as emails, pictures, search queries, locations, or purchases -and use them for varied purposes.
Some uses materialize into outputs visible to users, such as ads, product or video recommendations, or prices.
Others invisible to the users.
XRay correlates some visible data inputs with some visible outputs by monitoring them, correlating them, and reporting strong associations to users.
An example association is which email(s) contributed to the selection of a particular ad.XRay relates only strongly correlated inputs with outputs.
If an output is strongly correlated to an input (i.e., the input's presence or absence changes the output), then XRay will likely be able to detect its use.
If not (i.e., the monitored input plays but a small role in the output), then it may go undetected.
XRay also relates small combinations of inputs with strongly correlated outputs.Although simple, this model efficiently addresses several types of personal data functions, including product recommendations, price discriminations, and various personalization functions (e.g., search, news).
We refer to such functions generically as targeting functions and focus XRay's design on them.Three popular forms of targeting are: 1.
Profile Targeting, which leverages static or slowly evolving explicit information -such as age, gender, race, or location -that the user often supplies by filling a form.
This type of targeting has been studied profusely [10,47,21,20,31]; we thus ignore it here.
2.
Contextual Targeting, which leverages the content currently being displayed.
In Gmail, this is the currently open email next to which the ad is shown.
In Amazon or Youtube, the target is the product or video next to which the recommendation is shown.
3.
Behavioral Targeting, which leverages a user's past actions.
An email sent or received today can trigger an ad tomorrow; a video watched now can trig-ger a recommendation later.
Use of histories makes it harder for users to track which data is being used, a key motivation for our development of XRay.Theoretically, our differential correlation algorithms could be applied to all three forms of targeting.
From a systems perspective, XRay's design is geared towards contextual targeting and a specific form of behavioral targeting.
The latter requires further attention.
We observe that this broad targeting class subsumes multiple types of targeting that operate at different granularities.
For example, a service could use as inputs a user's most recent few emails to decide targeting.
This would be similar to an extended context.
Alternatively, a service could use historical input to learn a user's coarse interests or characteristics and base its targeting on that.XRay currently aims to disclose any targeting applied at the level of individual user data, or small combinations thereof.
Our differential correlation algorithms could be applied to detect targeting that operates on a coarser granularity.
However, the XRay system itself would require significant changes.
Unless otherwise noted, we use behavioral targeting to denote the restricted form of behavioral targeting that XRay is designed to address.
We formalize these restrictions in §4.2.
To further narrow our problem's scope, we introduce threat assumptions.
We assume that data owners (users and auditors) are trusted and do not attempt to leverage XRay to harm Web services or the Web ecosystem.
While they trust Web services with their data, they wish to better understand how that data is being used.
Data owners are thus assumed to upload the data in clear text to the Web services.The threat models relevant for Web services depend on the use case.
For example, Scenarios 1 and 2 in §2.1 assume Google is trusted, but its users wish to understand more about how advertisers target them through its ad platform.
In contrast, in Scenarios 3 and 4, investigators may have reason to believe that Web services might intentionally frustrate auditing.
This paper assumes an honest-but-curious model for Web services: they try to use private data for financial or functional gains, but they do not try to frustrate our auditing mechanism, e.g., by identifying and disabling shadow accounts.
The service might attempt to defend itself against more general types of attacks, such as spammers or DDoS attacks.
For example, many Web services constrain the creation of accounts so as to limit spamming and false clicks.
Similarly, Web services may rate limit or block the IPs of aggressive data collectors.
XRay must be robust to such inherent defenses.
We discuss challenges and potential approaches for stronger adversarial models in §7.
XRay's design addresses the preceding goals and assumptions.
For concreteness, we draw examples from our three XRay instantiations: tracking emailto-ad targeting association within Gmail, attributing recommended videos to those already seen on YouTube, and identifying products in a wish list that generate a recommendation on Amazon.
XRay's high-level architecture ( Figure 2) consists of three components: (1) a Browser Plugin, which intercepts tracked inputs and outputs to/from an audited Web service and gives users visual feedback about any input/output associations, (2) a Shadow Account Manager, which populates shadow accounts with inputs from the plugin and collects outputs (e.g., ads) for each shadow account, and (3) the Correlation Engine, XRay's core, which infers associations and provides them to the plugin for visualization.
While the Browser Plugin and Shadow Account Manager are service specific, the Correlation Engine, which encapsulates the science of Web-data tracking, is service agnostic.
After we describe each component, we focus on the design of the Correlation Engine.
Browser Plugin.
The Browser Plugin intercepts designated inputs and outputs (i.e., tracked inputs/outputs) by recognizing specific DOM elements in an audited service's Web pages.
Other inputs and outputs may not be tracked by XRay (i.e., untracked inputs/outputs).
The decision of what to track belongs to an investigator or developer who instantiates XRay to work on a specific service.
For example, we configure the XRay Gmail Plugin to monitor a user's emails as inputs and ads as outputs.
When the Plugin gets a new tracked input (e.g., a new email), it forwards it both to the service and to the Shadow Account Manager.
When the Plugin gets a new tracked output (e.g., an ad), it queries the Correlation Engine for associations with the user's tracked inputs (message get assoc).
Shadow Account Manager.
This component: (1) populates the shadow accounts with subsets of a user account's tracked inputs (denoted D i ), and (2) periodically retrieves outputs (denoted O k ) from the audited service for each shadow account.
Both functions are service specific.
For Gmail, they send emails with SMTP and call the ad API.
For YouTube, they stream a video and scrape recommendations, and for Amazon, they place products in wish lists and scrape recommendations.
The complexity of these tasks depends on the availability of APIs or the stability of a service's page formats.
Outputs collected from the Web service are placed into a Correlation Database (DB), which maps shadow accounts to their input sets and output observations.
Figure 2 shows a par- Differential Correlation Engine.
This engine, XRay's service-agnostic "brain," leverages the data collected in the Correlation DB to infer input/output associations.
When new outputs from shadow accounts are added into the Correlation DB, the engine attempts to diagnose them using a Correlation Algorithm.
We developed several such algorithms and describe them in §4.3.
This process, potentially time-consuming process, is done as a background job, asynchronously from any user request.
In Figure 2, differential correlation might conclude that D 2 triggers O 1 because O 1 appears consistently in accounts with that D 2 .
It might also conclude that O 2 is untargeted given inconsistent observations.
The engine saves these associations in the Correlation DB.When the plugin makes a get assoc request, the Correlation Engine looks up the specified output in its DB and returns any pre-computed association.
If no output is found, then the engine replies unknown (e.g., if an ad never appeared in any shadow account or there is insufficient information).
Periodic data collection, coupled with an online update of correlation model parameters, minimizes the number of unknown associations.
Our experience shows that collecting shadow account outputs in Gmail every ten hours or so yielded few unknown ads.While the preceding example is simple, XRay can handle complex challenges occurring in practice.
First, outputs are never consistently seen across all shadow accounts containing the input they target.
We call this the limited-coverage problem; XRay handles it by placing each data input in more shadow accounts.
Second, an output may have been triggered by one of several targeted inputs (e.g., multiple emails on the same topic may cause related ads to appear), a problem we refer to as overlapping-inputs.
This exacerbates the number of accounts needed, since it diminishes the differential signal we receive from them.
XRay uses robust, service-agnostic mechanisms and algorithms to match overlapping inputs, place them in the same accounts, and detects their use as a group.
Organization.
The remainder of this section describes the Differential Correlation Engine.
After constructing it for Gmail, we applied it as-is for Amazon and YouTube, where it achieved equally high accuracy and scalability despite observable differences in how targeting works on these three services.
After establishing notations and formalizing our assumptions ( §4.2), we describe multiple correlation algorithms, which build up to our self-tuning correlation algorithm that made this adaptation convenient ( §4.3).
§4.4 describes our input matching.
We use f to denote the black-box function that represents the service (e.g., Gmail) associating inputs D i s (e.g., the emails received and sent) to targeted outputs O k s (e.g., ads).
Other inputs are either ignored by XRay, known only to the targeting system, or under no known control.
We assume they are independent or fixed, captured in the randomness of f .
We assume that f decides targeting using: (1) is in the account).
We refer to conjunctive and disjunctive combinations as AND and OR combinations, respectively, and assume that their is bounded by a maximum input size, r.
This corresponds to the preceding definition of behavioral targeting from §3.2.
Contextual targeting will always be a single-input (size-one) combination.Our goal is to decide whether f produced each output O k as a reaction to a bounded-size combination of the D i s.
We define as untargeted any ad that is not targeted against any combination of D i s, though in reality the ad could be targeted against untracked inputs.
We denote untargeting as D / 0 , meaning that the ad is targeted against the "void" email.
Our algorithms compute the most likely combination from the N inputs that explains a particular set of observations, 񮽙 x, obtained by XRay.We define three probabilities upon which our algorithms and analyses depend.
First, the coverage, p in , is the probability that an account j containing the input D i targeted by a particular ad, will see that ad at least once.
Second, an account j 񮽙 lacking input D i will see the ad with a smaller probability, p out .
Third, if the ad is not behaviorally targeted, it will appear in each account with the same probability, p / 0 .
We assume that p in , p / 0 , p out are constant across all emails, ads, and time, and that p out is strictly smaller than p in (bounded noise hypothesis).
Finally, we consider all outputs to be independent of each other across time.
§8 discusses the implications.
A core contribution of this paper is our service-agnostic, self-tuning differential correlation algorithm, which requires only a logarithmic number of shadow accounts to achieve high accuracy.
We wished not only to validate this result experimentally, but also to prove it theoretically in the context of our assumptions.
This section constructs the algorithm in steps, starting with a na¨ıvena¨ıve polynomial algorithm that illustrates the scaling challenges.
We then define a base algorithm using set intersections and prove that it has the desired logarithmic scaling properties; it has parameters which, if not carefully chosen, can lead to poor results.
We therefore extend this base algorithm into a self-tuning Bayesian model that automatically adjusts its parameters to maximize correctness.
An intuitive approach to differential correlation is to create accounts for every combination of inputs, gathering maximum information about their behaviors.
With a sufficient number of observations, one could expect to detect which accounts, and hence which subsets of inputs, target a particular ad.
Unfortunately, this method requires a number of accounts that grows exponentially as the number of items N to track grows.
When restricting the size of combinations to r, as we do in XRay, the number of accounts needed is polynomial (in O(N r )), or linear if we study unique inputs only.
Even a linear number of accounts in the number N of inputs remains impractical to scale to large input sizes (e.g., a mailbox).
We now show that it is possible to infer behavioral targeting using no more than a logarithmic number of accounts as a function of the number of inputs.
Specifically, we prove the following theorem:Theorem 1 Under §4.2 assumptions, for any ε > 0 there exists an algorithm that requires C × ln(N) accounts to correctly identify the inputs of a targeted ad with probability (1 − ε).
The constant C depends on ε and the maximum size of combinations r (O(r2 r log( 1 ε ))).
To demonstrate the theorem, we define the Set Intersection Algorithm and prove that it has the correctness and scaling properties specified in the theorem.
Given that outputs will appear more often in accounts containing the targeting inputs, the core of the algorithm is to determine the set of inputs appearing in the highest number of accounts that also see a given ad.
This paper describes a basic version of the algorithm that makes § ¤ some simplifying assumptions and provides a brief proof sketch.
The detailed proof and complete algorithm are described in our technical report [26].
Algorithm.
The algorithm relies on a randomized placement of inputs into shadow accounts, with some redundancy to cope with imperfect coverage.
We thus pick a probability, 0 < α < 1, create C ln(N) shadow accounts, and place each input D i randomly into each account with probability α.
Figure 3 shows the Set Intersection algorithm for a set of observations, 񮽙 x. Given an output O k collected from the user account, we compute the set of active accounts, A k , as those shadow accounts that have seen the output (Step 1).
We then compute the set of inputs that appear in at least a threshold fraction of active accounts; this set is our candidate for the combination being targeted by the ad (Step 2).
Finally, we check that the entire combination is in a threshold fraction of the active accounts (Step 3).
Theoretically, we prove that there exists a threshold for which the algorithm is arbitrarily correct with the available C ln(N) accounts.
Practically, this threshold must be tuned experimentally to achieve good accuracy on every service -a key reason for our Bayesian enhancement in §4.3.3.
Correctness Proof Sketch.
The proof shows that if there were targeting, every non-targeting input would have a vanishingly small probability to be in a significant fraction of the active accounts.
Let us call S the set of inputs § ¤ // Bayesian Prediction Alg: // Runs with each collected ad.
In: Output O k (e.g. an ad).
contained in a significant fraction of the active accounts.
Without targeting, these inputs would be present in the accounts by mere chance.
Since inputs are independently distributed into the accounts, we show that the probability of S not being empty decreases exponentially with the number of active accounts (through Chernoff bounds).
Out: Targeted input.
// Compute probabilities.
foreach input D i do P [D i | 񮽙 x ] = bayes(P [񮽙 x| D i ]) end // Compute untargeted prob.
P [D / 0 | 񮽙 x ] = bayes(P [񮽙 x| D / 0 ]) //With targeting, we show that with high probability no other input than the explaining combination is in S, because of the bounded noise hypothesis.
Appendix A.2 provides further proof details.
The proofs and algorithm included in this paper work only for conjunctive combinations (e.g., D 1 and D 2 , see §4.2).
The theory, however, can be extended to disjunctive combinations (e.g., (D 1 and D 2 ) or D 5 ), but the algorithm for detecting such combinations is more complex and relies on a recursive argument: if we find one combination from the disjunction, then the active accounts that include this combination define a context where the combination appears non-targeting because it is everywhere.
If we recursively apply our algorithm in this context, we can detect the second combination in the disjunction, then the third, etc (see technical report [26]).
The Set Intersection algorithm provides a good theoretical foundation; however, it requires parameters be tuned and applies only to behavioral targeting, not contextual targeting.
Thus, we include in XRay a more robust, self-tuning version that leverages a Bayesian algorithm to adjust parameters automatically through iterated inference.
Our algorithm relies on three models: one that predicts behavioral targeting, one that predicts contextual targeting, and one that combines the two.
Behavioral Targeting.
The Bayesian behavioral targeting model uses the same random assignment as the Set Intersection algorithm, and it leverages the same information from the shadow account observations, 񮽙 x.
It counts the observations x j of ad O k in an account j as a binary signal: if the ad has appeared at least once in account j, we count it once; otherwise we do not count it.
Briefly, the Bayesian model is a simple generative model that simulates the audited service given some targeting associations (e.g., D i triggers O k ).
It computes the probability for this model to generate the outputs we do observe for every targeting association.
The most likely association will be the one XRay returns.In more detail if the ad were targeted towards D i , then an account j containing D i would see this ad at least once with a coverage probability p in ; otherwise, it would miss it with probability (1 − p in ).
An account j 񮽙 without input D i would see the ad with a smaller probability, p out , missing it with probability (1 − p out ).
If the ad were not behaviorally targeted, it would appear in each account with the same probability, p / 0 .
If we define A k as the set of active accounts that have seen the ad, and A i as the set of accounts that contain email D i , then we have the following definitions for the probabilities:P [񮽙 x| D i ] = (p in ) |A i ∩A k | (1 − p in ) |A i ∩ ¯ A k | × (p out ) | ¯ A i ∩A k | (1 − p out ) | ¯ A i ∩ ¯ A k | , P [񮽙 x| D / 0 ] = (p / 0 ) |A k | (1 − p / 0 ) | ¯ A k | ,where D / 0 designates the untargeted prediction.
The preceding formula has an interesting interpretation that is visible if placed in the equivalent form:P [񮽙 x| D i ] = (p in ) |A k | (1 − p out ) | ¯ A k | × 񮽙 1 − p in 1 − p out 񮽙 |A i ∩ ¯ A k | 񮽙 p out p in 񮽙 | ¯ A i ∩A k |From the point of view of the event D i , an account found in A i ∩ ¯ A k is a false positive (an ad was expected but was not shown).
This should lower the probability, especially when the coverage p in is close to 1.
Inversely, an account found in ¯ A i ∩ A k acts as a false negative (we observed an ad where we did not expect it), which should decrease the probability, especially when p out is close to 0.
These formulas let us infer the likelihood of event .
Figure 4 shows two algorithms.
First, the prediction algorithm (left) predicts the targeting of O k by computing the probabilities defined above, applying Bayes' rule, and returning the input with the maximum probability.
Second, the parameter learning algorithm (right) computes the variables that those probabilities depend upon (p in , p out , and p / 0 ) using an iterative process.
It repeatedly runs the prediction algorithm for all outputs and re-computes p in , p out , and p / 0 based on the predictions.
It stops when the variables converge (i.e., their variation from one iteration to another is small).
Contextual Targeting.
Contextual targeting is more straightforward since it uses content shown next to the ad.
XRay also uses Bayesian inference and defines the observations as how many times ad O k is seen next to email D i .
Our causal model assumes imperfect coverage: if this ad were contextually targeted towards D i , it would occur next to that email with probability p in < 1 and next to any other email with probability p out .
Alternatively, if the ad were untargeted, our model predicts it would be shown next to any email with probability p / 0 .
Hence,P [񮽙 x|D i ] = (p in ) x i (p out ) ∑ i 񮽙 񮽙 =i x 񮽙 i , P [񮽙 x|D / 0 ] = (p / 0 ) ∑ i x i .
For this model, parameters are also automatically computed by iterated inference.
Composite Model (XRay).
The contextual and behavioral mechanisms were designed to detect different types of targeting.
To detect both types, XRay must combine the two scores.
We experimented with multiple combination functions, including a decision tree and the arithmetic average, and concluded that the arithmetic average yields sufficiently good results.
XRay thus defines the composite model that averages scores from individual models, and we demonstrate in §6.3 that doing so yields higher recall for no loss in precision.
Our design of differential correlation, along with our logarithmic results for random input placement, relies on the fundamental assumption that the probability of getting an ad O 1 targeted at an input D 1 in a shadow account that lacks D 1 is vanishingly small.
However, when inputs attract the same ads (a.k.a., overlapping inputs), a naive input placement can contradict this assumption.
Imagine a Gmail account with multiple emails related to a Caribbean trip.
If placement includes Caribbean emails in every available shadow account, related ads will appear in groups of accounts with no email object in common.
XRay will thus classify them as untargeted.Our Amazon experiments showed XRay's recall dropping from 97% to 30% with overlapping inputs ( §6.5).
To address this problem, XRay's Input Matching module identifies similar inputs and directs the Placement Module to co-locate them in the same shadow accounts.
The key challenge is to identify similar inputs.
One method is to use content analysis (e.g., keywords matching), but this has limitations.
First, it is not service agnostic; one needs to reverse engineer complex and ever-changing matching schemes.
Second, it is hard to apply to non-textual media, such as YouTube videos.In XRay, we opt for a more robust, systems technique rooted in the key insight that we can deduce similar inputs from contextual targeting.
Intuitively, inputs that trigger similar targeting from the Web service should attract similar outputs in their context.
The Input Matching module builds and compare inputs' contextual signatures.
Contextual signature similarity is the distance between inputs (e.g., email) in a Euclidean space, where each output (e.g., ad) is a dimension.
The coordinate of an email in this dimension is the number of times the ad was seen in the context of the email.
XRay then forwards close inputs to the same shadow accounts.
Once the placement is done, behavioral targeting against that email's group can be inferred effectively.This input matching mechanism differs fundamentally from any content analysis technique, such as keyword matching, because it groups inputs the same way the Web service does.
2 It is robust and very general: we used it on both Gmail and Amazon without changing a single line of code to change.
To evaluate XRay's extensibility, we instantiated it on Gmail, YouTube, and Amazon.
The engine, about 3,000 lines of Ruby, was first developed for Gmail.
We then extended it to YouTube and Amazon, without any changes to its correlation algorithms.
We did need to do minor code re-structuring, but the experience felt turn key when integrating a new service into the correlation machinery.Building the full toolset required non-trivial coding effort, however.
Instantiating XRay for a specific Web service is a three-step process.
First, the developer instantiates appropriate data models (less than 20 code lines for our prototypes).
Second, she implements a service-specific shadow account manager and plugin; care must be taken not be too aggressive to avoid adversarial service reactions.
While these implementations are conceptually simple, they require some coding; our Amazon and YouTube account managers were built by two graduate students new to the project, and have around 500 lines of code.
Third, the developer creates a few shadow accounts for the audited service and runs a small exploratory experiment to determine the service's coverage.
XRay uses the coverage to estimate the number of shadow accounts needed for a given input size.
All other parameters are self-tuned at runtime.
We evaluated XRay with experiments on Gmail, Amazon, and YouTube.
While Amazon and YouTube provide ground truth for their targeting, Gmail does not.
We therefore manually labeled ads on Gmail and measured XRay's accuracy, as described in §6.
1 We evaluated XRay with experiments on Gmail, Amazon, and YouTube.
For inputs, we created a workload for each service by selecting topics from well-defined categories relevant for that service.
For Gmail and YouTube, we crafted emails and selected videos based on AdSense categories [17]; for Amazon, we selected products from its own product categories [2].
We used these categories for most of our experiments ( §6.3- §6.5).
We used these categories to create two types of workloads: (1) a nonoverlapping workload, in which each data item belonged to a distinct category, and (2) an overlapping workload, with multiple data items per category (described in §6.5).
To assess XRay's accuracy, we needed the ground truth for associations.
Amazon and YouTube provide it for their recommendations.
For instance, Amazon provides a link "Why recommended?"
which explicitly explains the recommendation.
For Gmail, we manually labeled ads based on our personal assessment.
The ads for different experiments were labeled by different people, generally project members.
A non-computer scientist labeled the largest experiment (51 emails).
We evaluate two metrics: (1) recall, the fraction of positive associations labeled as such, and (2) precision, the fraction of correct associations.
We define high accuracy as having both high recall and high precision.
To build intuition into XRay's functioning, we ran a simple sanity-check experiment on Gmail.
Recall that, unlike Amazon and YouTube, Gmail does not provide any ground truth, requiring us to manually label associations, a process that can be itself faulty.
Before measuring XRay's accuracy against labeled associations, we checked that XRay can detect associations for our own ads, whose targeting we control.
For this, we strayed away from the aforementioned methodology to create a highly controlled experiment.
We posted four Google AdWords campaigns targeted on very specific keywords (Chaldean Poetry, Steampunk, Cosplay, and Falconry), crafted an inbox that included one email per keyword, and used XRay to recover the associations between our ads and those emails.
In total, we saw our ads 1622, 912, 442, and 1608 times, respectively, across all accounts (shadows and master).
Figure 5 shows our results.
After one round of ad collection (which involved 50 refreshes per email), XRay correctly associated all four ads with the targeted email.
It did so with very high confidence: composite model scores were 0.99 in all cases, with very high scores for both contextual and behavioral models.
The figure also shows some of the raw contextual/behavioral data, which provides intuition into XRay's perfect precision and recall in this controlled experiment.
We next turn to evaluating XRay in less controlled environments, for which we use the workloads and labeling methodology described in §6.1.
To assess the accuracy of XRay's key correlation mechanisms (Bayesian behavioral, contextual, and composite), we measured their recall and precision under non-overlapping workloads.
Figures 6(a) and 6(b) show how these two metrics varied with the number of shadow accounts for a 20-email experiment on Gmail.The results indicate two effects.
First, both contextual and behavioral models were required for high recall.Of the 193 distinct ads seen in the user account, 121 (62%) were targeted, and XRay found 109 (90%) of them, a recall we deem high.
Of the associations XRay found, 37% were found by only one of the models: 15 by the contextual model only, and 24 by the behavioral model only.
Thus, both models were necessary, and composing them yielded high recall.
Our Amazon and YouTube experiments (which provide ground truth) yielded very similar results: on a 20-input experiment, we reached over 90% recall and precision with only 8 and 12 accounts, respectively.Second, the composite model's recall exhibited a knee-shaped curve for increasing shadow account numbers, with a rapid improvement at the beginning and slow growth thereafter.
With 16 accounts, XRay exceeded 85% recall; increasing the number of accounts to 100 yielded a 1.9% improvement.
Precision also remained high (over 84%) past 16 accounts.
We define the knee as the minimum number of accounts needed to reap most of the achievable recall and precision.We also wished to compare the accuracy of the Bayesian algorithm, which conveniently self-tunes its parameters, to the parameterized Set Intersection algorithm.
We manually tuned the latter as best as we could.
Figures 7(a) and 7(b) show the recall and precision for detecting behavioral targeting with the two methods for a non-overlapping workload.
The two algorithms performed similarly, with the Bayesian staying within 5% of the manually tuned algorithm.
We also tested the algorithms on an Amazon dataset, and using a version of the Set Intersection algorithm with empirical optimizations.
The conclusion holds: the Bayesian algorithm, with self-tuned parameters, performs as well as the Set Intersection technique with manually tuned parameters.
We focus the remainder of this evaluation on the Bayesian algorithm.
A main contribution of this paper is the realization that, under certain assumptions, the number of accounts needed to achieve high accuracy for XRay scales logarithmically with the number of tracked inputs.
We have proven that under certain assumptions, the Set Intersection algorithm scales logarithmically.
This theoretical result is hard to extend to the Bayesian algorithm, so we evaluated it experimentally by studying three metrics with growing input size: the number of accounts required to reach the recall knee and the value of recall/precision at this knee.
Figures 8(a), 8(b) and 8(c) show the corresponding results for Gmail, YouTube and Amazon.
For Gmail, the number of accounts necessary to reach the knee increased less than 3-fold (from 8 to 21) as input size increased more than 25-fold (from 2 to 51).
For Amazon and YouTube, the increases in accounts were 6-and 8-fold respectively, for a 32-fold increase in input size.
In general, the roughly linear shapes of the log-x-scale graphs in Figure 8(a) confirm the logarithmic increase in the number of accounts required to handle different inputs.
Figure 8(b) and 8(c) confirm that the "knee number" of accounts achieved high recall and precision (over 80%).
What accounts for the large gap between the number of accounts needed for high accuracy in Gmail versus Amazon?
For example, tracking a mere two emails in Gmail required 8 accounts, while tracking two viewed products in Amazon needed 2 accounts.
The distinction corresponds to the difference in coverage exhibited by the two services.
In Gmail, a targeted ad was typically seen in a smaller fraction of the relevant accounts compared to a recommended product in Amazon.
XRay adapted its parameters to lower coverage automatically, but it needed more accounts to do so.Overall, these results confirm that our theoretical scalability results hold for real-world systems given carefully crafted, non-overlapping input workloads.
We next investigate how more realistic overlapping input workloads challenge the accuracy of our theoretical models and how input matching -a purely systems technique -helps address this challenge.
To evaluate XRay's accuracy with overlapping inputs, we infused our workloads with multiple items from the same category.
(e.g., multiple emails targeting the same topic on Gmail and multiple products in the same category in Amazon).
For the Gmail experiments, we (as users) could not tell when Gmail targeted a specific email from a group of similar emails.
We therefore ran two different types of experiments.
First, a controlled, albeit unrealistic, one for Gmail.
We replicated various emails identically in a user's inbox: 1 email was replicated 4 times, 2 emails 3 times, 4 emails 2 times, and 12 were single, for a total of 30 emails.
This end-of-a-spectrum workload demonstrates how matching works ideally.
XRay matched all redundant emails correctly.
More importantly, Figures 9(a) and 9(b) show XRay's precision/recall with and without matching-aware placement for XRay's behavioral model, the only model improved by matching.
Without input matching, XRay struggled to find differential signals: even with 35 shadow accounts for a 30-email experiment, recall was only 48%.
With input matching, XRay's correlation model drew a stronger signal from each account and attained close to 70% recall for 16 accounts.Second, for Amazon, we created a more realistic overlapping workload by selecting three distinct products in each of six product categories (e.g., from the Outdoor & Cycling category, we selected a helmet, pedals, and shoes).
With a total workload of 18 products, XRay's input matching matched all but one item (shoes) into its correct group.
With the new grouping, XRay's recall improved by a factor of 3 (from 30% to 93%) compared to the no-matching case for 18 products with 10 accounts; precision was 2.6 times higher (from 34% to 88%).
These results demonstrate that XRay's matching scheme is both portable across Web services and essential for high accuracy with overlapping workloads.
To gain intuition into XRay's practical value, we ran a small-scale, anecdotal experiment that fished for Gmail ads targeted against a few specific topics.
We created emails focused on topics such as cancer, Alzheimer, depression, HIV, race, homosexuality, pregnancy, divorce, and debt.
Each email consisted of keywords closely related to one topic (e.g., the depression-related email included depression, depressed, and sad; the homosexuality email included gay, homosexual, and lesbian).
We then launched XRay's Gmail ad collection and examined the targeting associations.
We acknowledge that a much larger-scale experiment is needed to reach statistically-meaningful conclusions.
Hence, we relate our experience by example.
Figure 10 shows ads that XRay associated with each topic, with its confidence scores.
Conservatively, we only consider ads with high scores.
We make two observations.
First, our small-scale experiment confirms that it is possible to target sensitive topics in users' inboxes.
All disease-related emails, except for the HIV one, are strongly correlated with a number of ads.
A "Shamanic healing" ad appears exclusively in accounts containing the depression-related email, and many times in its context; ads for assisted living services target the Alzheimer email; and a Ford campaign to fight breast cancer targets the cancer email.
Race, homosexuality, pregnancy, divorce, and debt also attract plenty of ads.
For example, the pregnancy email is strongly targeted by an ad for baby-shower invitations (shown in the figure), maternity-and lactation-related ads (not shown), and, interestingly, a number of ads for general-purpose clothing (shown).
As another example, the debt email is strongly targeted by a car dealership ad that entices the targeted users to take a Toyota test drive using a $50 gift offering.
Discussing the morality of targeting such sensitive topics is beyond our statute, however we believe that the lack of transparency, coupled with sensitive-topic targeting, opens users to subtle dangers, a topic we discuss next.Second, for many ads, the association with the targeted email is not obvious at all.
Nothing in the "Shamanic healing" ad suggests targeting against depression; nothing in the general-purpose clothing ads suggest targeting against pregnancy; and nothing in the "Cedars hotel" ad suggests an orientation toward the homosexuality email.
If no keyword in the ad suggests relation with sensitive topics, a user clicking on the ad may not realize that they could be disclosing private information to advertisers.
Imagine an insurance company wanted to gain insight into pre-existing conditions of its customers before signing them up.
It could create two ad campaigns -one that targets cancer and another youth -and assign different URLs to each campaign.
It could then offer higher premium quotes to visitors who come through the cancer-related ads to discourage them from signing up while offering lower premium quotes to those who come through youth-related ads.
We believe that the potential for this attack illustrates the urgent need for increased transparency in ad targeting.
Our evaluation results show that XRay supports finegrained, accurate data tracking in popular Web services, scales well with the size of data being tracked, is general and flexible enough to work efficiently for three Web services, and robustly uses systems techniques to discover associations when ad contents provide no indication of them.
We next discuss how XRay meets its last goal: robustness against honest-but-curious attackers.
As stated in §3.3, two threat models are relevant for XRay and applicable to different use cases.
First, an honest-but-curious Web service does not attempt to frustrate XRay, but it could incorporate defenses against typical Web attacks, such as DDoS or spam, that might interfere with XRay's functioning.
Second, a malicious service takes an adversarial stand toward XRay, seeking to prevent or otherwise disrupt its correlations.
Our current XRay prototype is robust against the former threat and can be extended to be so against the latter.
In either case, third-party advertisers can attempt to frustrate XRay's auditing.
We discuss each threat in turn.
Non-Malicious Web Services.
Many services incorporate protections against specific automated behaviors.
For example, Google makes it hard to create new accounts, although doing so remains within reach.
Moreover, many services actively try to identify spammers and click fraud.
Gmail includes sophisticated spam filtering mechanisms, while YouTube rate limits video viewing to prevent spam video promotion.
Finally, many services rate limit access from the same IP address.XRay-based tools must be aware of these mechanisms and scale back their activities to avoid raising red flags.
For example, our prototype for Gmail, YouTube, and Amazon rate limit their output collection in the shadow accounts.
Moreover, XRay's very design is sensitive to these challenges: by requiring as few accounts as possible, we minimize: (1) the load on the service imposed by auditing, and (2) the amount of input replication across shadow accounts.
Moreover, XRay's workloads are often atypical of spam workloads.
Our XRay Gmail plugin sends emails from one to a few other accounts, while spam is sent from one account to many other accounts.
Malicious Third-Party Advertisers.
Third-party advertisers have many ways to obfuscate their targeting from XRay, particularly if it may arouse a public outcry.
First, an advertiser could purposefully weaken its targeting by, for example, targeting the same ad 50% on one topic and 50% on another topic.
This weakens input/output correlation and may cause XRay to infer untargeting.
However, it also makes the advertisers' targeting less effective and potentially more ambiguous if their goal is to learn specific sensitive information about users.
Second, an advertiser might target complex combinations of inputs that XRay's basic design cannot discover.
Our accompanying technical report shows an example of how advertisers might achieve this [26].
It also extends our theoretical models so they can detect targeting on linear combinations with only a constant factor increase in the number of accounts.
We plan to incorporate and evaluate these extensions in a future prototype.
Malicious Web Services.
A malicious service could identify and disable shadow accounts.
Identification could be based on abnormal traffic (successive reloads of email pages), data distribution within accounts (several accounts with subsets of one account), and perhaps more.
XRay could be extended to add randomness and deception (e.g., fake emails, varying copies).
More importantly, a collaborative approach to auditing, in which users contribute their ads and input topics in an privacypreserving way is a promising direction for strengthening robustness against attacks.
Web services cannot, after all, disable legitimate user accounts to frustrate auditing.
We plan to pursue this direction in future work.
XRay takes a significant step toward providing data management transparency in Web services.
As an initial effort, it has a number of limitations.
First, both the Set Intersection and Bayesian algorithms assume independent targeting across accounts and over time.
In reality, ad targeting is not always independent across either.
For example, advertisers set daily ad budgets.
When the budget runs out, an ad can stop appearing in accounts midexperiment even though it has the targeted attributes.
The system might incorrectly assume that no targeting is taking place, when it could resume the next day.
XRay takes reduced coverage into account, but differences between ads can let some targeting pass unnoticed.
XRay does not currently account for these dependencies, but estimating their impact is an important goal for future work.Second, we assume that targeting noise is bounded and smaller than the targeting signal.
While this condition seems to hold on the evaluated services, other services making more local decisions may be harder to audit.
For example, Facebook might target ads based on friends' information, potentially creating noise that is as high as the targeting signal.
A future solution might imitate the social network in shadow accounts.Third, XRay uses Web services atypically.
To the best of our knowledge, it does not violate any terms of service.
It does, however, collect ads paid for by advertisers to detect correlation.
Ad payment is per impression and pay per click.
The former is vastly less expensive than the latter [32].
XRay creates false impressions only but never clicks on ads.
A back-of-the-envelope calculation using impression pricing from [32] of $0.6/thousand impressions reveals that XRay's cost should be minimal: at most 50 cents per ad for our largest experiments.Despite these limitations, XRay has proven itself useful for many needs, particularly in an auditing context.
An auditor can craft inputs that avoid many of these limitations.
For example, emails can be written to avoid as much overlap as possible and keep the size of inputs used for targeting within reasonable bounds.
We hope that XRay's solid correlation components will streamline much-needed investigations -by researchers, journalists, or the FTC -into how personal data is being used.
While §2.2 covered Web data protection and auditing related works, we next cover other related topics.
Our work relates to recent efforts to measure various forms of personalization, such as search [21,47], pricing [31], and ad discrimination [40].
They generally employ a methodology similar in spirit to differential correlation, but their goals differ from ours.
They aim to quantify how much output is personalized and what type of information is used overall.
In contrast, XRay seeks to provide fine-grained diagnosis of which input data generates which personalized results.
Through its scaling mechanisms -unique in the personalization and data tracking literature -XRay scales well even when the relevant inputs are many and unknown in advance.Our work also relates to a growing body of research measuring advertising networks.These networks, notably complex and difficult to crawl [3], are rendered opaque by the need to combat click fraud [9], and have been shown to be susceptible to leakage [24] and profile reconstruction attacks [6].
As for other personalization, prior studies focused mostly on macroscopic trends (e.g., What fraction of ads are targeted?)
[3] or qualitative trends (e.g., Which ads are targeted toward gay males?)
[20].
Various studies showed traces -but not a prevalence -of potential abuse through concealed targeting [20] and data exchange between services [46].
These works primarily focus on display advertising, and each distinguishes contextual advertising using a specific classifier with semantic categories obtained from Google's Ad Preferences Managers or another public API [28].
XRay departs significantly from these works.
First, since it entirely ignores the content and even the domain of targeting, it is readily applied as-is to ads in Gmail, product recommendations, and videos.
Second, while previous methods label ads as "behavioral" in bulk once other explanations fail [28], XRay remains grounded on positive evidence, and determines to which inputs an output should be attributed.
Third, XRay's mechanisms to avoid exponential input placement and deal with overlapping inputs are unprecedented in the Webdata-tracking context.
While they resemble black box software testing [4], the specific targeting assumption we leverage have, to our knowledge, no prior equivalent.
The tracking of personal data usage poses unique challenges.
XRay shows for the first time that accurate, fine-grained tracking need not compromise portability and scalability.
For users who care about which piece of their data has been targeted, it offers a unique level of precision and protection.
Our work calls for and promotes the best practice of voluntary transparency, while at the same time empowering investigators and watchdogs with a significant new tool for increased vigilance.A Proof of Theorem 1 A.1 Targeting functions, Axioms and Core Family A combination C of order r, also called r combination, is a subset of r elements among the N inputs.Each given ad is associated with a targeting function defined as a mapping f from any subset C of the N inputs into {0, 1}, where f (C ) = 1 denotes that an account containing C as inputs should be targeted.
By convention, untargeted ads are associated with the null function f (.)
= 0.
Any targeting function f satisfies two axioms:• monotonicity: C ⊆ C 񮽙 =⇒ f (C ) ≤ f (C 񮽙 ).
• input-sensitivity: ∃C , C 񮽙 s.t. f (C ) = 0, f (C 񮽙 ) = 1.
Monotonicity simply reflects that an account with strictly more interest or hobbies should in theory be relevant to more ads, and never to less.
Input sensitivity prevents the degenerate case where a targeting function is constant.A family S of size l is any collection of l distinct combination.
The order of this family is defined as the largest order of a combination it contains.
For any family S, one can define a targeting function that takes value 1 whenever the subset contains at least one combination in S. Indeed, as shown in [26], the converse is true:Lemma 1 For each monotone, input-sensitive targeting function there exists a unique family S satisfying:(i) S has size l and order r and it explains f , which means f (C ) = 1 holds if and only if ∃C 񮽙 ∈ S, C 񮽙 ⊆ C .
(ii) No family of size l 񮽙 < l explains f .
(iii) No family of order r 񮽙 < r explains f .
Hence, associated with each ad and therefore each targeting function is a unique family of input combination that are targeted, called the ad's core family, and we now sketch why it is correctly identified by our algorithm.
For any family of subsets S and fraction 0 ≤ x ≤ 1, we say a subset of inputs C is an x intersecting subset of S if x subsets in S have at least one input in C .
Our proof exploits an original connection between small intersecting subsets (that can be found efficiently) to show how they can reveal a core family.
One way to understand why is the following: say, for instance, that the targeting function f takes value 1 exactly when one of the inputs within C is found in the account.
Then C is exactly the union of inputs found in the core family and intersects all accounts within scope, i.e., forms a large fraction of those receiving the ad.The key property to explain our algorithm is random subsets.
We can show under the conditions of the theorem that there exists 0 < x < 1 that satisfies two properties related to the inputs of accounts receiving the ads: (1) if targeting does not occur, then with a large probability we cannot find a subset of l inputs that meets at least a fraction x of the accounts seeing the ad, and (2) if targeting does occur, we have accounts receiving the ads for various reasons, within and outside the targeting scope.
But we can show with high probability that at least a fraction x of them are within scope and hence must include one combination in the core family.
Since with each core family of size l one can associate an intersecting subset that contains at most l elements, checking the existence of such a subset reveals the presence of targeting.This explains why an algorithm can qualitatively conclude whether targeting occurs or not, but it does not explain how the core family can be computed.
However, leveraging stronger results of random subsets allows to apply the same rule recursively, offering multiple ways to determine exactly the core family even with a polynomial number of operations.More formally, we define: A random Bernoulli subset, denoted by B(n, p), is a subset such that any of n elements is contained with probability p independently of all others.
A random Bernoulli family of size m is a collection of m independent Bernouilli subsets.
We first show property (1) above more formally:Lemma 2 Let x > 0, s ∈ N, p < 1 − (1 − x)1 s , and a Bernouilli family B 1 (n, p), B 2 (n, p),.
.
.
,B m (n, p).
For any ε > 0 and polynomial P of degree ≤ r, there exists A > 0 such that with probability 񮽙 1 − ε P(n)񮽙 no x intersection subset exists of size s whenever we have: m ≥ A · ((s + r) ln(n) + ln(1/ε)) .
To prove property (2), we need to bound, among accounts receiving an ad, the fraction that is outside the scope of targeting but still receives the ads because p out > 0.
Formally, we have:Lemma 3 Let x > 0, α > 0, and a core family of size l and order r p in , p out where we have p out /p in < 1−x x α r 1−α r .
Let C be a combination of order r.For any ε > 0 and polynomial P of degree ≤ r, there exists A > 0 such that with probability (1 − ε/P(n)) the following holds: Among accounts containing C and receiving the ad, at least x fraction of them is within the targeting scope whenever we have: m ≥ A · (r ln(n) + ln(1/ε)) .
The two lemmas above (proved in [26]) can be combined whenever α satisfies the inequality for p in the first lemma, which shows that an algorithm can detect the presence of targeting whenever A naive exponential algorithm could be used to exhaustively search for a core family using this brick.
We also show that a polynomial algorithm can refine this analysis to compute the core family at the expense of a more complex recursion in [26].
We thank our shepherd, Dan Boneh, the anonymous reviewers, and numerous colleagues (Jonathan Bell, Sandra Kaplan, Michael Keller, Yoshi Kohno, Hank Levy, Yang Tang, Nicolas Viennot, and Junfeng Yang) for their valuable feedback.
This work was supported by DARPA Contract FA8650-11-C-7190, NSF CNS-1351089 and CNS-1254035, Google, and Microsoft.
