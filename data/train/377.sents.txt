Data aggregation protocols can reduce the cost of communication, thereby extending the lifetime of sensor networks.
Prior work on data aggregation protocols has focused on tree-based or cluster-based structured approaches.
Although structured approaches are suited for data gathering applications, they incur high maintenance overhead in dynamic scenarios for event-based applications.
The goal of our work is to design techniques and protocols that lead to efficient data aggregation without explicit maintenance of a structure.
As packets need to converge spatially and temporally for data aggregation, we propose two corresponding mechanisms-Data-Aware Anycast at the MAC layer and Randomized Waiting at the application layer.
We model the performance of the combined protocol that uses both the approaches and show that our analysis matches with the simulations.
Using extensive simulations and experiments on a testbed with implementation in TinyOS, we study the performance and potential of structure-free data aggregation.
In sensor networks, the communication cost is often several orders of magnitude higher than the computation cost.
For optimizing the communication cost in-network data aggregation is considered an effective technique.
The inherent redundancy in raw data collected from the sensors can often be eliminated by in-network data aggregation.
In addition, such operations are also useful for extracting application specific information from the raw data.
To conserve energy for a longer network lifetime, it is critical for the network to support high incidence of in-network data aggregation.Various centralized structured approaches [1]- [4] have been proposed for aggregation in data gathering applications where all nodes periodically report to the sink.
Due to the unchanging traffic pattern, structured aggregation techniques incur low maintenance overhead and are therefore suited for such applications.
Various distributed structured approaches have been proposed for event-based applications [5]- [7].
However there are several limitations of structured aggregation techniques for event-based applications.
First, for dynamic scenarios the overhead of construction and maintenance of the structure may outweigh the benefits of data aggregation.
Second, some distributed approaches such as [5] assume that there is a well defined center-of-event and that the measured strength of the sensed signal is an indicator of the distance to the center of the event.
For amorphous events, such as biological hazard, chemical hazard, or fire detection, absence of an explicit center or any evident point for optimal aggregation makes such approaches inapplicable.
Third, structured approaches that centrally compute the aggregation tree [4] are not practical for dynamic scenarios due to excessive communication overhead for centralized computation.
And fourth, the performance of structured approaches is sensitive to the waiting period (for data from all upstream nodes) at the intermediate nodes.
A small period can lead to fewer number of aggregations and a long period can lead to higher latency.
Moreover, computing the optimal period requires knowledge of the relative position of the node with respect to its entire subtree, which may not be known accurately especially for dynamic scenarios.In this paper we explore the potential of structure-free data aggregation for event-based sensor networks.
The goal of our work is to design techniques and protocols that lead to efficient data aggregation without explicit maintenance of a structure.
To the best of our knowledge this is the first study on the topic of structure-free data aggregation in sensor networks.
A combination of a partial structured approach with our structure-free approach may further improve performance, but it is outside the scope of this paper.There are two main challenges in performing structure-free data aggregation.
First, as there is no pre-constructed structure, routing decisions for efficient aggregation of packets need to be made on-the-fly.
Second, as nodes do not explicitly know their upstream nodes, they can not explicitly wait on data from any particular node before forwarding their own data.The contributions of this paper are four-fold.
First, we observe that packets need to be aggregated early on their route to the sink for efficiency.
Based on this observation we propose and model a MAC layer protocol for spatial convergence called Data-Aware Anycast (DAA).
Second, we observe that if some nodes wait for other nodes to send data, it can lead to efficient aggregation.
We study the impact of Randomized Waiting (RW) for improved data aggregation.
Third, we perform detailed evaluation using simulations to establish the benefits of structure-free data aggregation.
And fourth, we implement the randomized waiting approach on TinyOS and test the randomized waiting approach in an indoor network of 6 Mica2 motes.The organization of the rest of the paper is as follows.
Section II presents background and related work.
Section III presents the DAA and RW protocols.
The performance of the combined approach that uses both DAA and RW is modeled in Section IV.
The performance evaluation of the protocols using simulations is presented in Section V. Results from the indoor testbed confirming the benefits of the RW approach are presented in Section VI.
Discussion and future work are presented in Section VII.
Finally Section VIII concludes the paper.
Because of the energy constraint of wireless sensor networks and relatively expensive communication cost, the computation cost of sensor nodes becomes less significant.
Pottie and Kaiser [8] reported that the energy consumption for executing 3000 instructions is equivalent to sending a bit 100 meters by radio.
For this reason, data aggregation, data-centric routing and in-network processing are very important to extend the lifetime of wireless sensor networks.
For routing packets while facilitating data aggregation, various protocols have been proposed.
They can be categorized into two families: cluster-based and tree-based.
This section briefly reviews these protocols by their structure categories and provides the motivation for our work.
LEACH [1] [2] and PEGASIS [9] are representatives of this family.
In [1], the authors propose the LEACH protocol to cluster sensor nodes and let the cluster-heads aggregate data and communicate directly with the base station.
To distribute energy consumption evenly among all nodes, the cluster-heads are randomly elected in each round.
In [2], authors propose a modified version named LEACH-C.
LEACH-C uses the basestation to broadcast the cluster-head assignment, thus further spreading out the cluster heads evenly throughout the network and extending the network lifetime.
Based on LEACH, [10] refines the cluster-head election algorithm by letting every node broadcast and count neighbors at each setup stage, where qualified potential nodes bid for the cluster head position.
This modification scatters cluster heads more evenly across the network without requiring the participation of the basestation.
As it also requires every node to broadcast at its highest transmission power at the setup stage of each round, it achieves only slight improvement (6% or so) over LEACH.Reducing the number of cluster-heads is critical to conserve energy as these nodes stay awake and transmit to the basestation using high power.
Lindsey et al. designed PEGASIS [3], which organizes all nodes in a chain and lets them play the role of heads in turn.
Since there is only one head node in PEGASIS and there is no simultaneous transmissions, latency is a issue faced by PEGASIS.
To address this, Lindsey et al. propose two chain-based PEGASIS enhancements in [9], [11].
[11] is a binary hierarchical approach for CDMA-capable sensor nodes, and [9] is a chain-based three level approach that allows simultaneous transmission for non-CDMA-capable sensor nodes.
These two approaches usually save less energy than PEGASIS, but outperform PEGASIS in Energy ×Delay metric.
Based on both LEACH and PEGASIS, Culpepper et al. propose Hybrid Indirect Transmission (HIT) [12], a hybrid scheme of these two.
HIT still uses LEACH-like clusters, but allows multi-hop routes between cluster-heads and non-head nodes.LEACH and PEGASIS based protocols assume that the base-station can be reached by any node in only one hop, which limits the size of the network for which such protocols are applicable.
The combination of CSMA, TDMA and CDMA makes the design complex and cost-inefficient.
In addition, in scenarios where the data can not be perfectly aggregated, LEACH-based protocols do not necessarily have significant advantage since the cluster-head has to send many packets to the base station using high transmission power.
In addition, the chain-based nature of PEGASIS-based protocols makes them suitable only for the scenario where packets can be perfectly aggregated into one packet of equal size.
Protocols in this family are built on traditional shortest path routing tree.
The research is focused on how to choose a good routing metric based on data attributes to facilitate data aggregation.
Directed Diffusion [13] [14] is one of the earliest to propose attribute-based routing.
Data can be opportunistically aggregated when they meet at any intermediate node.
Based on Directed Diffusion, the authors propose Greedy Incremental Tree (GIT) in [7] [15].
GIT establishes an energy-efficient path and attaches other sources greedily onto the established path.
Heidemann et al. [16] further study the effect of data aggregation on Directed Diffusion through experimentation.
Krishnamachari et al. [17] compare three data-centric routing schemes, Center at Nearest Source (CNS), Shortest Path Tree (SPT) and another version of Greedy Incremental Tree (GIT) which establish the route between the sink the the nearest source first, to illustrate the advantage of data aggregation for saving energy.
They observe that GIT performs the best in terms of average number of transmissions.
In [18] [19] Madden et al. study the data aggregation issue in implementing a real system and propose the Tiny AGgregation Service (TAG) framework.
TAG uses shortest path tree, and proposes improvements like snooping-based and hypothesis testing based optimizations, dynamic parent switching, and using child cache to estimate lost data.
TAG lets parents notify their children about the waiting time to gather all data from children before transmitting, and the sleeping schedule can be adjusted accordingly.
Ding et al. use shortest path tree with parent energy-awareness in [20], where the neighbor node of shortest distance to the sink with higher residual energy is chosen as parent.
All the above tree-based data aggregation routing protocols need a lot of message exchange to construct and maintain the tree.Most of these tree-based aggregation routing protocols are not designed for event tracking applications.
GIT can be used in such a scenario, but it suffers from the cost of pruning branches, which might lead to high cost in moving event scenarios.
Zhang and Cao propose Dynamic Convoy TreeBased Collaboration (DCTC) in [5].
In [6], Zhang and Cao further optimize the tree reconfiguration schemes.
Essentially, DCTC tries to balance the tree in the monitoring region to reduce the energy consumption.
But it assumes the knowledge of distances to the center of the event at sensor nodes, which may not be feasible to compute with the sensed information in all tracking applications.
In addition, DCTC involves heavy message exchanges, which is not desired when the data rate is high, and the performance of DCTC highly depends on the accuracy of mobility prediction algorithms.
For optimal aggregation nodes must transmit their packets in a certain order.
Structured approaches are designed to follow such orderings for achieving optimal aggregation.
For example the transmissions should proceed from the leaves to the root for a tree.
Structured approaches though suited for data gathering applications, have high overhead for event-based applications, as discussed in Section I.
The other extreme is to use opportunistic aggregation where packets are aggregated only if they happen to meet at the same node at the same time while being forwarded to the sink.
In opportunistic aggregation, there is no overhead of aggregation structure construction, however it may not result in efficient data aggregation like in the structured approaches.
In fact, without explicit coordination, the performance of the opportunistic aggregation technique is non-deterministic, and the chance of aggregation may be limited.
To avoid the overhead of structured approaches and the limitations of opportunistic aggregation, we study the design of structure-free techniques for data aggregation.Spatial convergence and temporal convergence during transmission are two necessary conditions for aggregation.
Packets have to be transmitted to the same node at the same time so they can meet and aggregate.
Structured approaches achieve these two conditions by letting nodes transmit packets to their parents in the aggregation tree and parents wait for packets from all its children before transmitting their packets.
Without explicit message exchange in structure-free aggregation, nodes do not know where they should send packets to and how long they should wait for aggregation.
Therefore improving spatial convergence or temporal convergence can improve the chance of aggregation.
We propose the Data-Aware Anycast (DAA) protocol for improving spatial convergence and the Randomized Waiting (RW) technique for improving temporal convergence.
These two approaches are described in the rest of this section.For the design of the structure-free convergence protocol we have the following goals.1) Early aggregation: Packets must get aggregated as early as possible on their journey to the sink.
2) Tolerance to event dynamics: If the event's region of influence is changing due to mobility, the overhead must not increase and the aggregation performance must remain unchanged.
3) Robust to interference: Intermittent link failures should not affect the aggregation performance.
4) Fault tolerance: The aggregation performance must not be affected by node failures which are common in sensor networks.
S A B C D E S A B C D E S D E A B C S A B C D E S A B C D E (a) (b) S D E A B C routeThree packets left in the network.Two packets left in the network.
In this section we present the Data-Aware Anycast (DAA) protocol which achieves all the goals described above.
When nodes send packets to the sink, they may follow different routes dictated by the routing protocol, even if they are close to each other.
Figure 1 shows an example comparing opportunistic aggregation with optimal forwarding strategy.
Figure 1(a) shows the packet transmissions assuming opportunistic aggregation.
Figure 1(b) shows how information about existence of data in neighboring nodes can be exploited to make dynamic forwarding decisions to achieve higher aggregation.
The black nodes represent nodes that have packets to send.
Because there is no message exchange to construct a structure for aggregation, packets from C and E follow two different routes that are constructed by the routing protocol.
The distributed MAC protocol determines the order of transmissions in case of opportunistic aggregation which does not achieve any aggregation in this case.
As the packet transmission from B to A occurs before transmission from C to B, the packets don't get aggregated.
However, as shown in Figure 1(b), if node C knows that node B does not have any packet for aggregation but node E does, it can send the packet to E for immediate aggregation.
As a result there are only two packets left in the network (as opposed to 3 for opportunistic aggregation).
This shows that if the routing protocol provides the freedom to the MAC layer to decide among a set of nodes (rather than a single next-hop), and if it can determine which node has packets for aggregation, efficient spatial convergence can be achieved.
In typical deployments of sensor networks, nodes have multiple choices for the next-hop node.
For example, in the ExScal [21] demonstration of the world's largest sensor network, each sensor had anywhere between 3 to 32 nodes in its communication range.We present the mechanisms of the DAA approach by discussing the base approach and enhancements to the base approach.
• DAA -The base approach: Our approach is based on anycasting [22]- [24] at the MAC layer for determining the next-hop node for each transmission.
Anycasting requires the use of RTS packets to elicit CTS responses from the neighbors before transmission of the packet.
We define the Aggregation ID (AID) to associate two packets that can be aggregated.
The RTS contains the AID of the transmitting packet and any neighbor that has a packet with the same AID can respond with a CTS.
In this paper we use the measurement timestamp as the AID.
Therefore two packets that are generated at the same time can potentially be aggregated.
As there could be multiple receivers capable of aggregating the packet, the receivers randomly delay the CTS transmission to avoid CTS collision.
Figure 2 shows the difference between unicasting in 802.11 and randomized CTS response in anycasting.
The interference between the neighbors of the sender can prevent multiple CTS transmissions.
Nodes will cancel their CTS transmission if they receive any packet during the random delay.
An interference range of more than twice of the transmission range suffices for causing the desired interference.
Unicast vs. Anycast: (a) In 802.11, the receiver sends a CTS immediately after receiving the RTS.
(b) In our approach, the receiver sends a CTS with a random delay to avoid collision between nodes sending the CTS.
The CTS of receiver 2 has longer delay and hence is canceled after hearing CTS from the receiver 1.
• Metric based prioritized CTS: Using the above approach, packets will converge to a few nodes which we call the aggregation points.
These aggregation points are selected dynamically without explicitly constructing the aggregation tree.
However, it is possible that the packets might be forwarded away from the sink.
In order to reduce the chance of packets being forwarded away from the sink, we give higher priority to nodes that are closer to the sink than the sender for sending the CTS.
Higher priority can be assigned by choosing a shorter random delay before sending the CTS.
The metric for proximity could be any metric including geographic distance or number of hops, and is discussed in detail later in this section.
• DAA on all hops: To further increase aggregation, we also use the DAA approach rather than unicast while forwarding packets from the aggregation points to the sink.
However, in order to forward the packet to the sink using the DAA approach, we enhance the mechanism as follows.
Instead of dropping RTS if the nodes do not have the packet for aggregation, they reply with the CTS if they are closer to the sink, but with lower priority than nodes that have packets for aggregation.
Therefore, packets are still aggregated when they have the chance to meet, otherwise the packets are forwarded greedily toward the sink.
shows routes taken by packets before they reach the aggregation points (black nodes) where they first fail to get aggregated any further.
Although most transmissions make progress toward the sink while aggregating, we observe that some transmissions move the packets away from the sink for the sake of aggregation.
We now discuss details of the CTS priorities, and the distance metrics.CTS Priorities: Nodes are assigned different priorities in responding to RTS.
The three classes of priorities are as follows:Class A: The receiver has the packet with the same ID as specified in RTS, and is closer to the sink than the sender.
Class B: The receiver has the packet with the same ID as specified in RTS, but is farther away from the sink than the sender.
Class C: The receiver does not have the packet with the same ID, but is closer to the sink than the sender.If the receiver does not have the packet with the same ID, and is also farther from the sink than the sender, it does not send a CTS.
Corresponding to these three classes of neighbors that can respond to the RTS, three slots are reserved for the CTS packets providing exclusively higher priorities for Class A over Class B, and Class B over Class C (Figure 4).
Nodes in the same class select a mini-slot to send their CTS to avoid collision with other nodes in the same class.
Among nodes in the same class, higher priority (earlier mini-slot) is given to nodes closer to the sink.
Note that the actual transmission time of the CTS could be larger than the mini-slot or slot time.
The slots and mini-slots are used to stagger the starting time of CTS transmissions based on the priorities.
Based on the assumption of interference between neighbors, we expect only the first CTS transmission to succeed since the others will Distance Metrics: In the DAA protocol, nodes need to know whether they are closer to the sink than the sender to set the priority for sending the CTS.
This priority is used for selecting the CTS-slot and also the mini-slot within a CTSslot.
We can use geographic distance to compare the distance to the sink between two nodes.
Nodes have to know their location and also the sink's location.
Furthermore, nodes have to know their neighbors' location.
Neighbors' location can be either contained in the RTS packet so the receivers can learn the sender's location, or can be exchanged between neighbors during network deployment.
Geographic voids and protocols to go around voids have been well studied [25], [26].
The DAA approach can be easily adapted to account for voids.
For example the perimeter-mode forwarding approach for dealing with voids [25] can make use of the anycast approach where Class A and Class C can be restricted only to the designated next-hop on the perimeter.
Therefore in the perimeter mode the packet can be forwarded to the designated next-hop if it has a packet (Class A), or it can be aggregated at another neighbor (Class B), or it can be forwarded to the designated next-hop without aggregation (Class C).
The DAA approach can also be used with other metrics such as the number of hops.
The main difference from the geographic approach is that the number of hops will be used to measure closeness to the sink rather than the geographic distance.The DAA approach meets the design goals outlined in the beginning of this Section.
The DAA approach is used at each hop resulting in aggregation as early as possible on the routes to the sink.
As there is no computed structure, event mobility has no impact on the performance of DAA.
As transmission links and next-hop nodes are chosen dynamically, DAA is tolerant to interference and node failures, and therefore is very robust even in unreliable networks.
However, in the DAA approach packets may not get aggregated if they are spatially separated (more than 1 hop) and if they are forwarded in lockstep by the MAC layer.
For such cases, we study the temporal convergence technique for improved performance.
The second condition for aggregation requires packets to be present in the same node at the same time.
Structure-free aggregation does not guarantee that aggregation will happen even when packets follow the same route.
If the order of packet transmissions do not result in packets meeting temporally at intermediate nodes, the benefit of aggregation may be limited.
The order of transmission may be governed by several factors including interference from other flows and interference from the same flow.Assume that the backoff intervals are much small in comparison to the packet transmission time.
For such a configuration, packets that are only a few hops apart may get forwarded in lock-step till they reach the sink even though they are on the same route.
To illustrate this point, consider a simple topology where all nodes are lined up in a chain as shown in Figure 5.
Suppose the radio signal can interfere with nodes that are two hops away.
If node D transmits first, node B and C will remain silent during the transmission.
Therefore no nodes will contend for the channel with A. Although C will send CTS packet and the channel will not be idle for node A, node A will only backoff for a short period, which is shorter than a packet transmission time, and node A will sense the channel as idle after that.
Since there is no contention, node A will send its packet, and its packet will not be aggregated with other packets from upstream nodes.
Note that when packets are more than one hops apart or when packets follow the same route, the DAA approach is ineffective in improving aggregation.
Deterministically assigning the waiting time to nodes such that nodes closer to the sink wait longer before transmitting can avoid the problem described above and increase the chance of aggregation.
However this results in a fixed delay for all packets wherever the packets are generated, close to or far away from the sink, and the delay incurred by the waiting time is proportional to the size of the network.
The delay would be intolerable in large network deployment.Therefore we propose Randomized Waiting (RW) at the source for each packet to introduce artificial delays and increase temporal convergence.
Each node generating a new packet to transmit, delays it by an interval chosen from 0 to τ , where τ is the maximum delay.
If node A chooses a higher delay than node D and nodes B and C have lower delays than A or D, node D's packet may be aggregated at node A if the difference between the delays of A and D is greater than the transmission time from node D to A. Notice that with Randomized Waiting, it is possible that the packets may be transmitted out of order if the data sampling time is smaller than τ .
The optimum value of τ depends on the event size, i.e. the maximum hop distance between nodes that are generating packets.
If the maximum number of hops increases, the maximum delay should increase such that the difference between the delay chosen by two nodes increases.
If the difference between two delays are too close, packets will not be aggregated even if the downstream nodes have higher delay because the transmission time will be greater than the delay difference.
However if the maximum delay is too large, the end to end packet transmission latency will be too high.
If the application is not delay tolerant, a low value of τ will need to be used which can not reap the benefits of this approach.
We explore this trade-off in Section V.
In this section we model the performance in terms of the total number of packets transmitted in the network when both Data-Aware Aggregation and Randomized Waiting are used.
An alternate combinatorial analysis technique is shown for a special case that also validates the analysis.
Results from simulations match the analysis results closely.
In this section we compute the expected number of transmissions when both spatial and temporal convergence techniques are used together.
In a network where all nodes have data to send, if nodes can cooperatively construct an aggregation tree and transmit packets starting from leaves to the root, there are n − 1 transmissions where n is the number of nodes in the network since there are n − 1 edges in the constructed tree.To analyze the expected number of transmissions in a structure-free network, first we compute the probability that a packet will be aggregated.
We assume that each node in the network has a packet to transmit.
Each node picks a random delay for every packet that it originates.
If downstream nodes have higher delay than the upstream nodes, packets can be aggregated at the downstream nodes.
To simplify the analysis, we do not consider the transmission delay that may result in fewer aggregations.Let Y be the random variable representing the number of hops a packet has been forwarded when it is aggregated.
Let d v h = x be the normalized random delay between 0 and 1 chosen by v h where v h is a node that is h-hops away from the sink.
Consider a network where each node has an average of k choices for downstream nodes.
A packet can be forwarded i hops and be aggregated only if a) the packet is forwarded through i − 1 nodes and all these nodes have lower delay than the sender, and b) the i-th node has higher delay than the sender.
Therefore, for a node that is h hops away from the sink,P (Y = i) = 񮽙 x (i−1)k × (1 − x k ), if 0 < i < h x (i−1)k , if i = h(1)The expected value of Y when the delay is x for node v h is:E[Y |d v h = x] = h 񮽙 i=1 i × P (Y = i) = 񮽙 h−1 񮽙 i=1 i × x (i−1)k (1 − x k ) 񮽙 + h × x (h−1)k = 񮽙 h−1 񮽙 i=1 i × x (i−1)k 񮽙 − 񮽙 h−1 񮽙 i=1 i × x ik 񮽙 + h × x (h−1)k = h−1 񮽙 i=0 x ik(2)Because x could be between 0 to 1, the expected value E [Y ] is thereforeE[Y ] = 񮽙 1 0 E[Y |d v h = x] dx = 񮽙 1 0 񮽙 h−1 񮽙 i=0 x ik 񮽙 dx = 񮽙񮽙 h−1 񮽙 i=0 x ik+1 ik + 1 񮽙񮽙 1 0 = h−1 񮽙 i=0 1 ik + 1(3)Using this expected value, we can calculate the expected number of transmissions in the network as:n/k 񮽙 h=1 k h−1 񮽙 i=0 1 ik + 1 = (n + 1)H k ( n k ) − n k(4)whereH k (n) = 񮽙 n i=1 1 (i−1)k+1is the summation of a harmonic sequence.
The above analysis assumes an uniform distribution for x in [0,1].
However the result is independent of the distribution.
Using an alternate combinatorial technique for the special case of k = 1, we obtain the same result.
We present the alternate technique (only for the special case) for validating our analysis and for the sake of completeness.Consider a chain topology of nodes v 0 to v n when node v 0 is the sink and all nodes have data to report to the sink.
Picking a number from 0 to 1 for each node is equivalent to choosing a random permutation corresponding to the order of transmissions.
As shown in Figure 6, for a packet generated at v n to be forwarded h hops, node v n must transmit later than all nodes within h − 1 hops, and earlier than the node at h hops away.
It is equivalent to randomly assigning n distinct numbers, s v1 to s vn , to these n nodes as their orders of transmissions such that among nodes v n−h through v n , s v n−h is the largest number and s vn is the second largest number.There are 񮽙 n h + 1 񮽙 possible combinations of selecting h+1numbers out of n numbers.
Among these selected h + 1 numbers, there are (h − 1)!
possible orderings such that s v n−h is the largest number and s vn is the second largest number.
The number of possible orderings of the rest of n − (h + 1) nodes is (n − (h + 1))!
Therefore the probability for a packet to be forwarded h hops is񮽙 n h + 1 񮽙 × (h − 1)!
× (n − (h + 1))!
n!
= 1 h(h + 1)If the packet travels to the sink without any aggregation, then all nodes on the route must have lower delay than the source.
For n nodes the fraction of permutations where a given node has the highest delay are 1 n .
Therefore,P (Y = i) = 񮽙 1 i(i+1) if 0 < i < n 1 n if i = n(5)and the expected value E[Y ] for node v n is:E[Y ] = n 񮽙 i=1 i × P (Y = i) = n−1 񮽙 i=1 i × 1 i(i + 1) + n × 1 n = n 񮽙 i=1 1 i(6)and the expected number of transmissions in the chain topology network isn 񮽙 h=1 h 񮽙 i=1 1 i = (n + 1)H 1 (n) − n (7) = (n + 1)(ln n + O(1)) − n (8) ≈ n ln n if n → ∞(9)We observe that this expression matches Equation 4 for k = 1, validating the previous analysis.
This alternate analysis also confirms that the expected number of packets is independent of the distribution used to choose the random number.
Sink n/k To compare the analytical results with simulations (using ns2) we use the network topology shown in Figure 7.
Each node has three downstream nodes within its transmission range.
In this simulation we only allow nodes to send packets to one of the 3 downstream nodes in the next column, and do not send packets to the nodes in the same column or nodes away from the sink.
This corresponds to k = 3 in our analysis.
We use τ = 50 for the maximum random delay for delaying packet transmission, where the unit is in expected transmission time for a single maximum sized packet.
Including the overhead of anycast for 50 byte packets this is approximately 0.04 seconds.
Therefore the maximum randomized waiting delay is 2 seconds.
Figure 8 shows the results of simulations and analysis.
It shows that the analysis results match the simulation results when the network size is less than 40 hops.
As the hop count increases, the number of transmissions measured from the simulations increases faster than the predictions of the analysis.
This difference is due to the absence of a model for transmission delay in our analysis.
As the number of hops increases the transmission delay also increases.
Therefore, a packet may not get aggregated at the downstream node which has higher delay due to non-negligible transmission delay.
As this effect increases with increasing number of hops, the discrepancy accordingly increases.
Note that with a larger value of τ the simulation results can be brought closer to the analysis for a wider range of number of hops.
Although the delay is introduced only at the source, the resulting end-toend delay may not be acceptable to the application if τ is very high.
In this section we evaluate the performance of our protocols and compare it with opportunistic aggregation.
The protocols evaluated are listed below: 1) Opportunistic (OP).
Nodes send their packets along the shortest path to the sink immediately when they get the measurements.
Packets are aggregated opportunistically.
2) Randomized Waiting (RW).
Nodes send their packets along the shortest path to the sink.
Packets are delayed at the source and are aggregated opportunistically.
3) Data Aware Anycast (DAA).
Nodes use spatial convergent anycast to aggregate packets without delaying at the source as described in section III-A.
(DAA+RW).
Both DAA and RW approaches are used.
We use the ns2 network simulator to evaluate the performance of these protocols.
The RTS/CTS packet formats of 802.11 MAC are modified to incorporate the anycasting capability.
The RTS contains an extra field of Aggregation ID and CTS packet contains an extra field of the address of the sender.
In all scenarios there is only one sink in the network and geographic distance is used to compare the distance from nodes to the sink.
We assume that nodes know their neighbors' location.The network is a 1000m x 1000m square region with grid topology.
The sink is located at one corner of the grid network.
The data rate of the radio is 38.4Kbps and the communication range is 50m.
An event moves in the network using the random way-point mobility model for 200 seconds.
Nodes generate packets with 50 bytes payload, and send packets to the sink every 5 seconds.
For an event size of radius of 200m with 25m as the distance between two nodes, there are 200 nodes generating packets at the same time (or 50 nodes generating packets if the distance between two nodes is 50m).
Unless otherwise mentioned, the inter-node separation is 30m, the event moving speed is 10m/s with a pause time of 0 second, and the radius of the event is 200m.
All simulation results are based on 10 different mobility scenarios (each for 200 seconds).
The minimum and maximum value obtained are also drawn in all graphs.The normalized number of transmissions is used as the metric to compare different protocols.
Normalized number of transmissions represents how effective a protocol is in aggregating packets and is (Number of transmissions in the network)/(Number of Contributing Sources).
The Number of Contributing Sources is the effective information that are generated by all sources in the network and are aggregated at the sink.
The number of aggregation is not a good metric since packets might be forwarded many hops before being aggregated, and reducing the number of transmissions is a key design goal.
The number of transmissions will be lower if more packets are aggregated early on their routes to the sink.
However the number of transmissions could be low if a lot of packets are dropped.
Therefore we use the normalized number of transmissions as the metric to compare different protocols.
First we evaluate the performance of the RW approach for achieving temporal convergence.
Using the default scenario (30m inter-node separation, 200m event radius and 10m/s event speed), there are around 140 nodes generating packets at the same time and each node has about 8 neighbors in its communication range.
We vary the maximum delay from 0 (no delay) to 4 seconds, which is approximately 100 packet transmission time.
Figure 9 shows the results.The performance of protocols OP and DAA do not change because there is no delay in these two protocols.
For protocols RW and DAA+RW, the normalized number of transmissions decreases as the maximum delay increases.
From 9(a) we can see that the DAA+RW has about 11% lower normalized number of transmissions than DAA, and is about 77% of the OP approach.
Although with higher values of τ the normalized load of DAA+RW can be further reduced, beyond τ = 50 the reduction is marginal.
Figure 10 shows the weighted delay for different value of maximum delay.
The weighted delay is the average delay experienced by a packet reaching the sink weighted by the number of contributing sources for that packet.
For example, suppose at time 2 the sink receives a packet generated at time 0 and this packet contains 3 aggregated packets.
At time 8, the sink receives another packet containing 4 aggregated packets which are generated at time 5, the weighted delay is ((2 − 0) * 3 + (8 − 5) * 4)/(3 + 4) = 18/7.
So, as the maximum delay increases, the average weighted delay also increases.
The delay of DAA and DAA+RW are slightly higher than the OP and RW.
That is because first OP and RW use shortest path to forward packets, and hence reduce the transmission time.
Second the packet dropping rate is high in OP and RW according to the collected data of the simulations.
The received packets are usually those packets that are sent first, and therefore have lower delay.We can see that introducing the randomized delay reduces the number of transmissions at the expense of increasing delay.
If the application is not tolerant to delay, DAA still provides good performance with reasonable delay.
In this simulation we evaluate the performance of our protocols in networks with varying node density.
With higher node density, packets are more likely to meet and get aggregated in DAA.
Figure 11 shows the simulation results for different protocols for different node densities.In this figure, the results of the OP and RW are not stable.
The normalized number of transmissions are higher in networks with higher node density.
Tracing into the details of the simulation results we found that the dropping rate of the packets are very high in these two approaches in dense networks.
About 40% to 70% packets are dropped during transmissions, compared with less than 5% to 20% drop rate for other two protocols.
Because the total number of transmissions includes packets that did not reach the sink, and the normalized number of transmissions is averaged over the number of received packets, the results are very sensitive to the number of dropped packets.From this figure we see that the normalized number of transmissions reduces when the node density increases for our protocols.
This is because in dense networks, more nodes are sending packets and packets have higher chance of being aggregated.
Among all protocols, DAA+RW performs the best in all scenarios, because it can achieve more aggregation using spatial and temporal convergence and reduce the number of transmissions.
Figure 12 shows the simulation results for different event moving speeds.
From the figure we can see that the results remain quite steady at different speeds.
As they do not create any structure for aggregation, mobility has little influence on the performance.
We have implemented the Randomized Waiting (RW) approach over unicast on the Kansei test-bed [27].
The Kansei test bed is composed of 195 stargates [28] arranged in a 15×13 grid.
Each stargate is attached with a XSM/Mica2 mote [29] through the serial port.
The stargates are used to create a wired network facilitating the reprogramming of XSMs and job dispatch.
Each attached XSM runs TinyOS [30].
It is equipped with multiple sensors and one CC1000 radio module [31].
This section introduces our experimental methodology and exhibits the advantage of using the RW approach for improving the performance of data aggregation.
The experimental topology is a 5-hop network with 6 XSM placed in a row (Fig. 13).
One XSM acts as the sink and the other 5 XSMs generate packets when they detect an "event".
We assume that all sensor nodes detect each event almost at the same time, and use perfect aggregation to combine any number of packets with the same sequence number (time-stamp in real deployed application) into a packet.
To mimic the event to trigger packet generation from XSM's at almost the same time, an event broadcast program runs on the Kansei server that connects directly to all the stargates through Ethernet.
This program is also in charge of broadcasting statistics query messages to all stargates.
There is another program running on these stargates to forward the event message and statistics query message to XSM attached to them, and to receive the statistics report message from the XSM and store in the disk.Each XSM waits for an event message, at which time it generates a 36-byte Active Message, inserts the current sequence number and its node ID into the data field, and puts it into the sending buffer.
The XSM delays sending it by starting a timer for a random period of time, and sends the packet to the MAC layer only when the timer expired.
If an XSM receives a packet with the same sequence number as the delayed packet before the timer expires, it aggregates the received packet into the delayed packet.
Otherwise it just puts the received packet in the sending buffer.
When the timer fires, the application calls the SendMsg() method of GenericComm to send the packet to the MAC layer, and never tries to retrieve the packet even if a new incoming packet has the same sequence number as that packet.The RW approach is compared to opportunistic aggregation (OP) in unicast, which is also implemented on TinyOS.
When a node running OP receives an event message from the attached stargate, it generates a packet and sends it to the GenericComm component without any delay.
When it receives a data packet, it does not try to fetch the packet from the MAC layer for aggregation.
Thus the only chance for opportunistic aggregation to happen is when a node has packet pending at the MAC layer and two or more packets with the same sequence number are received.
To compare the RW approach with opportunistic aggregation in unicast (denoted by maximum delay of 0 in graphs), the experiments are conducted for different value of maximum delay.
Since the link quality is not perfect and packets might be dropped, we use two normalized metrics to compare RW approach with OP approach, ratio of total transmissions vs. aggregations and ratio of total receptions vs. aggregations.
Here the aggregation means the total amount of effective information received by the sink.
In this paper, the information of a packet is measured by the number of different sources contributing to the content of this packet.
If the sink receives 10 packets and each of which contains the information from 5 source nodes, then the amount of information is counted as 5 × 10 = 50.
If a packet contains messages from more sources than another one, it has more information.The results are shown in Fig. 14 and Fig. 15.
Each point in the graph is obtained by generating 500 events.
Comparing the opportunistic aggregation with RW, we can see the former has more packet transmissions but the information received by the sink is less ( (Fig. 15).
The reason is that in opportunistic aggregation, few packets get aggregated, thus more packets are injected into the network, resulting in more contention losses.
Note that the maximum delay can be as low as 0.2s to achieve comparable performance as large delays (> 1s), which means that we do not necessarily incur high end-to-end delay by using the RW approach.
Further study of the optimal delay time will be part of our future work.
We have also gathered the information aggregated at each intermediate node.
When a packets arrives at an intermediate node, it may be aggregated to another packet or forwarded directly.
Obviously higher aggregation chance is desired.
Fig.
16 shows the information aggregated at each intermediate node (node ID from 1 to 4, node 0 is the sink, and node 5 is the most distant source).
It is clear from the graph that the aggregation rarely happens in opportunistic aggregation, while the RW approach achieves much more aggregation at intermediate nodes.
Max.delay=0.5s Max.delay=0.9sMax.delay=1s Max.delay=2sMax.
delay=3s We present some issues that were not addressed in this paper and are the focus of future or ongoing research.
Comparison with Structured Approaches: Although we have discussed the disadvantages of structure-free approaches over structured approaches in static scenarios, we have not addressed the question of -how much worse do structurefree approaches perform in static scenarios?
The difficulty of computing the proper waiting time may support the use of structure-free approaches even in static scenarios.
We plan to compare structured aggregation protocols with structure-free protocols both in simulations and experiments, for static as well as dynamic scenarios.
Semi-Structured Approach: While the structure-free approach has its advantages in dynamic scenarios, the structured approaches are suited for static scenarios.
A combined approach must smoothly adapt between the two by maintaining a partial structure for low maintenance overhead that is augmented by structure-free approaches.
Depending on the dynamics of the scenario, the partial structure may either become a full structure, or completely disappear and depend on structure-free approaches.
We are currently investigating the design for such combined approaches.
Anycast for other Aggregation Functions: The anycast technique uses an ID to identify packets that can be aggregated.
Assuming that packets with the same time-stamp can get aggregated, we have only focused on using the time-stamp as the ID.
However, for other aggregation functions, the ID can be a function of the data itself that can be smartly used to compute the extent of aggregation that can be achieved at the next-hop.
Such computations could be used to prefer forwarding nodes that can attain the most aggregation.
We plan to study the performance for a wider range of aggregation functions.
Research on data-aggregation protocols has focused on treebased or cluster-based structured approaches.
In this paper we proposed techniques for data aggregation that do not use any explicit structures.
Efficient aggregation requires packets to meet at the same node (spatial convergence) at the same time (temporal convergence).
For spatial convergence we proposed a MAC layer anycast based approach called Data-Aware Anycast (DAA).
For temporal convergence we proposed Randomized Waiting (RW) at the application layer at the source of the packet.
We model the network load generated by the combined DAA with RW approach and show that the predictions of the analysis match closely with the simulation results.
We define the normalized network load as the number of packets transmitted in the network normalized by the total amount of information (number of nodes whose packets reached the sink with or without aggregation) delivered to the sink.
Using extensive simulations we show that the combined DAA with RW approach can improve the normalized load by as much as 77%.
Based on the experimental study with 6 XSM sensor nodes we observe that RW can significantly reduce the normalized overhead in terms of number of transmissions.
This shows that structure-free data aggregation techniques have great potential for event-based applications.
